<!doctype html><html lang=es-es><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Cuando nos hablan de inteligencia artificial, nos asustamos y pensamos en primera instancia que estos conocimientos están lejos de la mano de los mortales.
En estas entradas voy a tratar de introducir de manera intuitiva los conceptos básicos del machine learning y presentar algunas implementaciones y aplicaciones, con el objetivo de aprender yo mismo, y que otra gente aprenda.
En este artículo tratamos uno de los modelos más básicos, la regresión lineal."><title>Inteligencia Artificial: #1 Introducción, rectas de regresión</title><link rel=canonical href=https://josecarlos.me/post/ia/ia-1-introduccion/><link rel=stylesheet href=/scss/style.min.css><meta property="og:title" content="Inteligencia Artificial: #1 Introducción, rectas de regresión"><meta property="og:description" content="Cuando nos hablan de inteligencia artificial, nos asustamos y pensamos en primera instancia que estos conocimientos están lejos de la mano de los mortales.
En estas entradas voy a tratar de introducir de manera intuitiva los conceptos básicos del machine learning y presentar algunas implementaciones y aplicaciones, con el objetivo de aprender yo mismo, y que otra gente aprenda.
En este artículo tratamos uno de los modelos más básicos, la regresión lineal."><meta property="og:url" content="https://josecarlos.me/post/ia/ia-1-introduccion/"><meta property="og:site_name" content="El blog de J. Carlos"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="ia"><meta property="article:tag" content="python"><meta property="article:tag" content="tensorflow"><meta property="article:published_time" content="2020-04-12T20:53:49+00:00"><meta property="article:modified_time" content="2020-04-12T20:53:49+00:00"><meta property="og:image" content="https://josecarlos.me/post/ia/ia-1-introduccion/cover.jpeg"><meta name=twitter:title content="Inteligencia Artificial: #1 Introducción, rectas de regresión"><meta name=twitter:description content="Cuando nos hablan de inteligencia artificial, nos asustamos y pensamos en primera instancia que estos conocimientos están lejos de la mano de los mortales.
En estas entradas voy a tratar de introducir de manera intuitiva los conceptos básicos del machine learning y presentar algunas implementaciones y aplicaciones, con el objetivo de aprender yo mismo, y que otra gente aprenda.
En este artículo tratamos uno de los modelos más básicos, la regresión lineal."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://josecarlos.me/post/ia/ia-1-introduccion/cover.jpeg"><link rel=alternate type=application/rss+xml href=https://josecarlos.me/post/ia/ia-1-introduccion/index.xml></head><body><div class="container flex on-phone--column align-items--flex-start extended article-page with-toolbar"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header class=site-info><figure class=site-avatar><img src=/img/me_hu2d3d9aacbf387919c2cd1f43f679ed29_15161_300x300_resize_q75_box.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar>
<span class=emoji>📏</span></figure><h1 class=site-name><a href=https://josecarlos.me>El blog de J. Carlos</a></h1><h2 class=site-description>Hello, world!</h2></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/sobre-mi><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>Sobre mi</span></a></li><li><a href=/archives><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archivos</span></a></li></ol></aside><main class="main full-width"><div id=article-toolbar><a href=https://josecarlos.me class=back-home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg><span>Back</span></a></div><article class="has-image main-article"><header class=article-header><div class=article-image><img srcset="/post/ia/ia-1-introduccion/cover_hua0b0fee973ceebe8dba5d8efb4cce1cf_142328_1024x0_resize_q75_box.jpeg 1024w, /post/ia/ia-1-introduccion/cover_hua0b0fee973ceebe8dba5d8efb4cce1cf_142328_2000x0_resize_q75_box.jpeg 2000w" src=/post/ia/ia-1-introduccion/cover_hua0b0fee973ceebe8dba5d8efb4cce1cf_142328_2000x0_resize_q75_box.jpeg width=2000 height=1768 loading=lazy alt="Featured image of post Inteligencia Artificial: #1 Introducción, rectas de regresión"></div><div class=article-details><header class=article-category><a href=/categories/ia/ class=color-tag data-image=/post/ia/ia-1-introduccion/cover_hua0b0fee973ceebe8dba5d8efb4cce1cf_142328_20x20_fill_q75_box_smart1.jpeg data-key=ia-1-introduccion data-hash="md5-UarmmQj1MjIaaqLutaWzCQ==">ia</a></header><h2 class=article-title><a href=/post/ia/ia-1-introduccion/>Inteligencia Artificial: #1 Introducción, rectas de regresión</a></h2><footer class=article-time><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--published>Apr 12, 2020</time></footer></div></header><section class=article-content><p>Cuando nos hablan de inteligencia artificial, nos asustamos y pensamos en primera instancia que estos conocimientos están lejos de la mano de los mortales.</p><p>En estas entradas voy a tratar de introducir de manera intuitiva los conceptos básicos del <em>machine learning</em> y presentar algunas implementaciones y aplicaciones, con el objetivo de aprender yo mismo, y que otra gente aprenda.</p><p>En este artículo tratamos uno de los modelos más básicos, la regresión lineal.</p><p><img src="https://images.unsplash.com/photo-1546188994-07c34f6e5e1b?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ" alt>
Photo by Drew Beamer / Unsplash</p><h1 id=predicciones-básicas>Predicciones básicas</h1><p>Supongamos que nos vamos a mudar a Boston, y <strong>estamos observando la relación entre el número de habitaciones y el precio de las viviendas.</strong></p><h2 id=recopilación-de-datos>Recopilación de datos</h2><p>Anotamos en una tabla los valores que hemos observado:</p><table><thead><tr><th>Precio vivienda</th><th>Nº de habitaciones</th></tr></thead><tbody><tr><td>24.0</td><td>6.575</td></tr><tr><td>21.6</td><td>6.421</td></tr><tr><td>34.7</td><td>7.185</td></tr><tr><td>33.4</td><td>6.998</td></tr><tr><td>36.2</td><td>7.147</td></tr><tr><td>28.7</td><td>6.43</td></tr><tr><td>22.9</td><td>6.012</td></tr><tr><td>27.1</td><td>6.172</td></tr><tr><td>16.5</td><td>5.631</td></tr><tr><td>18.9</td><td>6.004</td></tr></tbody></table><p>Un primer acercamiento que podemos hacer es <strong>dibujar una nube de puntos</strong> donde el eje de las X corresponda al número medio de habitaciones, y el eje de las Y corresponda al precio medio de la vivienda.</p><figure><img src=/blog/content/images/2020/09/dataset-scatter-3.png></figure><p>Una primera opción para resumir estos datos, es <strong>dibujar una recta que pase cerca de todos los datos</strong>, pero, ¿Cómo podemos hacerlo? ¿Podemos tantear la solución?</p><p>Parece que <strong>tratar de solucionar este problema por tanteo, no es factible</strong>, tratemos de buscar una solución aplicando las matemáticas.</p><h2 id=recta-de-regresión-lineal>Recta de regresión lineal</h2><p>Queremos calcular una recta que minimice los errores entre todos los puntos
<img src=/blog/content/images/2020/09/dataset-scatter-error-1.png alt=dataset-scatter-error-1></p><p>Si calculamos la media de estos errores y los elevamos al cuadrado, obtenemos lo que se denomina <strong>error cuadrático medio</strong>, y la recta que cumple esta propiedad se denomina <strong>recta de regresión lineal</strong>.</p><h3 id=fórmulas-para-el-cálculo-de-hiperplanos-de-regresión>Fórmulas para el cálculo de hiperplanos de regresión</h3><p>Si $X$ es la matriz de variables con una columna de $1$ en la primera columna, e $Y$ son los datos que tenemos y queremos predecir. Si observamos el caso de las viviendas en Boston, la matrix $X$ tendría dos columnas, una sólo con 1, y otra con la media de número de habitaciones, por otro lado, la $Y$ serían los precios de las viviendas.</p><p>Entonces, el hiperplano $Y_e=\beta X$ (O recta en $\mathbb{R}^2$) tiene las siguientes componentes:
$$ \beta = (X^T X)^{-1} X^T Y $$</p><p>Dado que la primera columna de $X$ está compuesta por 1, el hiperplano vendrá definido por:
$$
Y_e = \beta_1 X + \beta_0
$$
Donde $\beta_i$ son las componentes del vector $\beta$</p><h3 id=prediciendo-valores>Prediciendo valores</h3><p>Si volvemos a nuestro caso especifico, vamos a calcular los valores $\beta$ y $\alpha$.</p><p>Nuestra matrices $X$ e $Y$, vienen definidas de la siguiente forma:</p><p>$$
X=\left(\begin{matrix}
1 & 6.575 \<br>1 & 6.421 \<br>1 & 7.185 \<br>1 & 6.998 \<br>1 & 7.147 \<br>1 & 6.43 \<br>1 & 6.012 \<br>1 & 6.172 \<br>1 & 5.631 \<br>1 & 6.004
\end{matrix}\right), Y=\left(\begin{matrix}
24.0 \<br>21.6 \<br>34.7 \<br>33.4 \<br>36.2 \<br>28.7 \<br>22.9 \<br>27.1 \<br>16.5 \<br>18.9
\end{matrix}\right)
$$</p><p>Por tanto,
$$\beta=(-49.98256497, 11.82850406)$$
De donde,
$$
y_e=x b_1 + b_0
$$</p><p>Podemos pintar la recta con los gráficos para ver como se ajusta la recta:
<img src=/blog/content/images/2020/04/descarga.png alt=descarga></p><p>Supongamos ahora, que queremos calcular el precio estimado de una vivienda de 8 habitaciones, ahora simplemente deberíamos sustiuir en nuestra recta otros valores, y tendríamos:
$$
y_e = 8 \beta_1 + \beta_0 = 44
$$</p><p>Por lo cual, predecimos que valor de una vivienda de 8 habitaciones, tendrá un precio aproximadamente de 44k$</p><p><img src="https://images.unsplash.com/photo-1451153378752-16ef2b36ad05?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Colorful building corner">
Photo by Hernan Lucio / Unsplash</p><h2 id=cálculo-de-recta-de-regresión-lineal-python>Cálculo de recta de regresión lineal Python</h2><p>Para este ejemplo utilizaremos la librería de cálculo científico <strong>numpy</strong>, se puede encontrar el ejemplo aquí:</p><ul><li><a class=link href=https://colab.research.google.com/drive/1tNfC--BjaaOIPSGJbSMSKJcYG3ySS_hV target=_blank rel=noopener>Ejemplo básico con Numpy</a></li><li><a class=link href=https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html target=_blank rel=noopener>Usando funciones ya existentes para calcular la recta de regresión</a></li></ul><h2 id=limitaciones>Limitaciones</h2><p>En el ejemplo específico de los precios de las viviendas en Boston según el número de habitaciones, se puede observar que los datos están más o menos cercanos a la recta de regresión que hemos calculado, y que la nube de puntos se &ldquo;asemeja&rdquo; a una recta. Sin embargo, esto no es siempre así. Podría ocurrir que nuestros datos estén sumamente dispersos, y que nos fuese imposible encontrar una recta de regresión donde el error mínimo sea demasiado grande.</p><p>Es por eso, que se verán otros modelos más complejos que tratan de solucionar esto.</p><h1 id=aplicaciones>Aplicaciones</h1><p>Como hemos observado, estos modelos son muy básicos y presentan limitaciones, sin embargo son bastante potentes en ciertas situaciones para predecir comportamientos.</p><p>Por ejemplo, podemos usar este modelo para predecir métricas en bases de datos temporales como <a class=link href=https://prometheus.io/ target=_blank rel=noopener>Prometheus</a></p><h2 id=prediciendo-el-futuro-con-prometheus>Prediciendo el futuro con Prometheus</h2><p>Prometheus incluye dos funciones interesante en este sentido <a class=link href=https://prometheus.io/docs/prometheus/latest/querying/functions/#predict_linear target=_blank rel=noopener><strong>predict_linear</strong></a> que predice el valor de una serie temporal en el futuro usando regresión lineal.</p><p>Esta función nos puede servir para tantear el valor que tendrá una métrica en el futuro. Por ejemplo, si tenemos una métrica que cuenta la cantidad de usuarios conectados durante una campaña, podremos saber cuantos usuarios habrá dentro de un periodo de tiempo.</p><p>Por otro lado, tenemos la función <a class=link href=https://prometheus.io/docs/prometheus/latest/querying/functions/#deriv target=_blank rel=noopener><strong>deriv</strong></a>, que nos devuelve la pendiente de la recta de regresión lineal.</p><p>Esta pendiente nos permite calcular la velocidad con la que se está moviendo nuestra serie temporal y hacia que dirección. Por ejemplo, si tenemos una métrica que cubre el porcentaje de disco duro libre, y hacemos su derivada en los últimos 30 minutos, y nos da un valor negativo, podremos saber que se están escribiendo ficheros en el disco, además, dado que la pendiente de la recta modela la velocidad de crecimiento (o decrecimiento) de nuestros datos, podremos sacar conclusiones de cuando pasará algo.
<img src="https://images.unsplash.com/photo-1551288049-bebda4e38f71?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Speedcurve Performance Analytics">
Photo by Luke Chesser / Unsplash</p><h1 id=fuente--enlaces-de-interés>Fuente / Enlaces de interés</h1><p><a class=link href=https://en.wikipedia.org/wiki/Linear_regression target=_blank rel=noopener>https://en.wikipedia.org/wiki/Linear_regression</a></p><p><a class=link href=https://docs.scipy.org/doc/numpy/reference/routines.linalg.html target=_blank rel=noopener>https://docs.scipy.org/doc/numpy/reference/routines.linalg.html</a></p><p><a class=link href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html target=_blank rel=noopener>https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</a></p><p><a class=link href=https://docs.scipy.org/doc/numpy/index.html target=_blank rel=noopener>https://docs.scipy.org/doc/numpy/index.html</a></p><p><a class=link href=https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html target=_blank rel=noopener>https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html</a></p>COÑO
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></section><footer class=article-footer><section class=article-tags><a href=/tags/ia/>ia</a>
<a href=/tags/python/>python</a>
<a href=/tags/tensorflow/>tensorflow</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-contents--wrapper></aside><div class=disqus-container><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"el-blog-de-j-carlos"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><footer class=site-footer><section class=copyright>&copy; 2020 El blog de J. Carlos</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=1.0.5>Stack</a></b> designed by
<a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true style=display:none><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const customFont=document.createElement('link');customFont.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";customFont.type="text/css";customFont.rel="stylesheet";document.head.appendChild(customFont);}());</script><link rel=stylesheet href=/css/highlight/light.min.css media="(prefers-color-scheme: light)"><link rel=stylesheet href=/css/highlight/dark.min.css media="(prefers-color-scheme: dark)"></body></html>