<!doctype html><html lang=es-es><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Hasta el momento, ten√≠a contratado 4 VPS con una capacidad bastante limitada d√≥nde he desplegado mis dos principales proyectos personales, tungsteno.app y josecarlos.me. En estos servidores virtuales ten√≠a desplegado un cl√∫ster de Kubernetes con un total de 4vCPU y 8GB de RAM.
En las √∫ltimas semanas, he estado atento a las ofertas de servidores dedicados de Kimsufi, una empresa que alquila servidores dedicados antiguos a un precio reducido, y he conseguido contratar el servidor KS-11, por tanto, ahora tengo una CPU de 8 hilos y 16 GB de RAM, y aunque es lento, tambi√©n dispongo de 2TB de disco HDD."><title>Mi nueva infraestructura. Proxmox + Private Network + Terraform + VPN + Kubernetes (Rancher)</title><link rel=canonical href=https://josecarlos.me/p/mi-nueva-infraestructura/><link rel=stylesheet href=/scss/style.min.css><meta property="og:title" content="Mi nueva infraestructura. Proxmox + Private Network + Terraform + VPN + Kubernetes (Rancher)"><meta property="og:description" content="Hasta el momento, ten√≠a contratado 4 VPS con una capacidad bastante limitada d√≥nde he desplegado mis dos principales proyectos personales, tungsteno.app y josecarlos.me. En estos servidores virtuales ten√≠a desplegado un cl√∫ster de Kubernetes con un total de 4vCPU y 8GB de RAM.
En las √∫ltimas semanas, he estado atento a las ofertas de servidores dedicados de Kimsufi, una empresa que alquila servidores dedicados antiguos a un precio reducido, y he conseguido contratar el servidor KS-11, por tanto, ahora tengo una CPU de 8 hilos y 16 GB de RAM, y aunque es lento, tambi√©n dispongo de 2TB de disco HDD."><meta property="og:url" content="https://josecarlos.me/p/mi-nueva-infraestructura/"><meta property="og:site_name" content="El blog de J. Carlos"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="ops"><meta property="article:tag" content="proxmox"><meta property="article:tag" content="kubernetes"><meta property="article:tag" content="private-network"><meta property="article:tag" content="wireguard"><meta property="article:published_time" content="2021-02-27T10:00:50+00:00"><meta property="article:modified_time" content="2021-02-27T10:00:50+00:00"><meta property="og:image" content="https://josecarlos.me/p/mi-nueva-infraestructura/cover.jpeg"><meta name=twitter:title content="Mi nueva infraestructura. Proxmox + Private Network + Terraform + VPN + Kubernetes (Rancher)"><meta name=twitter:description content="Hasta el momento, ten√≠a contratado 4 VPS con una capacidad bastante limitada d√≥nde he desplegado mis dos principales proyectos personales, tungsteno.app y josecarlos.me. En estos servidores virtuales ten√≠a desplegado un cl√∫ster de Kubernetes con un total de 4vCPU y 8GB de RAM.
En las √∫ltimas semanas, he estado atento a las ofertas de servidores dedicados de Kimsufi, una empresa que alquila servidores dedicados antiguos a un precio reducido, y he conseguido contratar el servidor KS-11, por tanto, ahora tengo una CPU de 8 hilos y 16 GB de RAM, y aunque es lento, tambi√©n dispongo de 2TB de disco HDD."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://josecarlos.me/p/mi-nueva-infraestructura/cover.jpeg"><link rel=alternate type=application/rss+xml href=https://josecarlos.me/p/mi-nueva-infraestructura/index.xml><script async src="https://www.googletagmanager.com/gtag/js?id=G-1XM1B01M48"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-1XM1B01M48');</script></head><body><div class="container flex on-phone--column align-items--flex-start extended article-page with-toolbar"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header class=site-info><figure class=site-avatar><img src=/img/me_hu2d3d9aacbf387919c2cd1f43f679ed29_15161_300x300_resize_q75_box.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar>
<span class=emoji>üìè</span></figure><h1 class=site-name><a href=https://josecarlos.me>El blog de J. Carlos</a></h1><h2 class=site-description>Hello, world!</h2></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/sobre-mi><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>Sobre mi</span></a></li><li><a href=/archives><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archivos</span></a></li></ol></aside><main class="main full-width"><div id=article-toolbar><a href=https://josecarlos.me class=back-home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg><span>Back</span></a></div><article class="has-image main-article"><header class=article-header><div class=article-image><img srcset="/p/mi-nueva-infraestructura/cover_hu62ac29edb27c88406440be36699d617a_267149_1024x0_resize_q75_box.jpeg 1024w, /p/mi-nueva-infraestructura/cover_hu62ac29edb27c88406440be36699d617a_267149_2000x0_resize_q75_box.jpeg 2000w" src=/p/mi-nueva-infraestructura/cover_hu62ac29edb27c88406440be36699d617a_267149_2000x0_resize_q75_box.jpeg width=1500 height=1250 loading=lazy alt="Featured image of post Mi nueva infraestructura. Proxmox + Private Network + Terraform + VPN + Kubernetes (Rancher)"></div><div class=article-details><header class=article-category><a href=/categories/ops/ class=color-tag data-image=/p/mi-nueva-infraestructura/cover_hu62ac29edb27c88406440be36699d617a_267149_20x20_fill_q75_box_smart1.jpeg data-key=mi-nueva-infraestructura data-hash="md5-lJfuOqD3+shubZmkrKeFcA==">ops</a></header><h2 class=article-title><a href=/p/mi-nueva-infraestructura/>Mi nueva infraestructura. Proxmox + Private Network + Terraform + VPN + Kubernetes (Rancher)</a></h2><footer class=article-time><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--published>Feb 27, 2021</time></footer></div></header><section class=article-content><p>Hasta el momento, ten√≠a contratado 4 VPS con una capacidad bastante limitada d√≥nde he desplegado mis dos principales proyectos personales, tungsteno.app y josecarlos.me.
En estos servidores virtuales ten√≠a desplegado un cl√∫ster de Kubernetes con un total de 4vCPU y 8GB de RAM.</p><p>En las √∫ltimas semanas, he estado atento a las ofertas de servidores dedicados de <a class=link href=https://www.kimsufi.com/es/ target=_blank rel=noopener>Kimsufi</a>, una empresa que alquila servidores dedicados antiguos a un precio reducido, y he conseguido contratar el servidor KS-11, por tanto, ahora tengo una CPU de 8 hilos y 16 GB de RAM, y aunque es lento, tambi√©n dispongo de 2TB de disco HDD. Estas condiciones me ayudaron a decidirme a montar un Proxmox, con distintas m√°quinas virtuales montadas con Terraform, una red privada, un entorno propio de laboratorio y muchas otras opciones para probar.</p><div class=toc><h1>Tabla de contenido</h1><nav id=TableOfContents><ul><li><a href=#proxmox>Proxmox</a><ul><li><a href=#instalaci√≥n>Instalaci√≥n</a></li><li><a href=#configurando-una-red-privada-para-todas-las-m√°quinas-virtuales>Configurando una red privada para todas las m√°quinas virtuales</a></li><li><a href=#creando-template-con-debian-10-proxmox>Creando template con Debian 10 Proxmox.</a></li><li><a href=#creando-m√°quinas-con-terraform>Creando m√°quinas con Terraform.</a></li><li><a href=#vpn-wireguard-acceder-desde-fuera-a-la-red-virtual>VPN (Wireguard): Acceder desde fuera a la red virtual.</a></li><li><a href=#otras-m√°quinas-necesarias>Otras m√°quinas necesarias</a></li></ul></li><li><a href=#kubernetes-f√°cilmente-rancher>Kubernetes f√°cilmente: Rancher</a><ul><li><a href=#instalando-rancher>Instalando Rancher</a></li><li><a href=#creando-un-nuevo-cl√∫ster-de-kubernetes>Creando un nuevo cl√∫ster de Kubernetes.</a></li><li><a href=#primeras-configuraciones>Primeras configuraciones</a></li><li><a href=#desplegando-mis-aplicaciones>Desplegando mis aplicaciones</a></li></ul></li><li><a href=#conclusiones>Conclusiones</a></li></ul></nav><hr></div><h2 id=proxmox>Proxmox</h2><p>Proxmox Virtual Environment, o Proxmox VE, entorno de virtualizaci√≥n de servidores de c√≥digo abierto. Est√° en distribuciones GNU/Linux basadas en Debian con una versi√≥n modificada del Kernel RHEL y permite el despliegue y la gesti√≥n de m√°quinas virtuales y contenedores. Proxmox VE incluye una consola Web y herramientas de l√≠nea de comandos, y proporciona una API REST para herramientas de terceros. Dos tipos de virtualizaci√≥n son compatibles: los contenedores basados con LXC (a partir de la versi√≥n 4.0 reemplaza OpenVZ, utilizado en la versi√≥n 3.4, incluido3‚Äã), y la virtualizaci√≥n con KVM. Viene con un instalador e incluye un sitio Web basado en la interfaz de administraci√≥n.</p><h3 id=instalaci√≥n>Instalaci√≥n</h3><p>Desde Kimsufi, o OVH tienes la posibilidad de instalar directamente un dedicado con la imagen de Proxmox. Si tienes otro proveedor, que no ofrece la opci√≥n de instalarlo desde las opciones de &ldquo;despliegue&rdquo;, siempre puedes ver las <a class=link href=https://pve.proxmox.com/wiki/Category:Installation target=_blank rel=noopener>gu√≠as de instalaci√≥n en la Wiki de Proxmox</a>.</p><h3 id=configurando-una-red-privada-para-todas-las-m√°quinas-virtuales>Configurando una red privada para todas las m√°quinas virtuales</h3><p>En mi proveedor del dedicado, s√≥lo ofrecen la posibilidad de tener una IP p√∫blica por dedicado, as√≠ que he tenido que configurar una red privada, y con configuraciones de port forwarding para redirigir desde la IP p√∫blica, a las distintas m√°quinas virtuales seg√∫n el puerto.</p><p>Por defecto, mi servidor dedicado ven√≠a con estas interfaces de red:</p><pre><code>root@xxxx:~# ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
    valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
    valid_lft forever preferred_lft forever
2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master vmbr0 state UP group default qlen 1000
    link/ether 00:25:90:76:dd:00 brd ff:ff:ff:ff:ff:ff
3: enp2s0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000
    link/ether 00:25:90:76:dd:01 brd ff:ff:ff:ff:ff:ff
4: vmbr0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 00:25:90:76:dd:00 brd ff:ff:ff:ff:ff:ff
    inet &lt;ip publica&gt;/24 brd &lt;gateway&gt;.255 scope global dynamic vmbr0
    valid_lft 81716sec preferred_lft 81716sec
    inet6 &lt;ip publica&gt;/64 scope link
    valid_lft forever preferred_lft forever
</code></pre><p>Con la siguiente configuraci√≥n:</p><pre><code>auto lo
iface lo inet loopback

iface enp1s0 inet manual

iface enp2s0 inet manual

auto vmbr0
iface vmbr0 inet dhcp
    bridge-ports enp1s0
    bridge-stp off
    bridge-fd 0

auto vmbr1
</code></pre><p>Nuestro objetivo es crear un puente virtual en nuestro dedicado, d√≥nde desplegaremos las IPs de nuestras m√°quinas virtuales. Para ello, editamos el fichero <code>/etc/network/interfaces</code>, y a√±adimos al final:</p><pre><code>auto vmbr1 # Nombre de la interfaz
iface vmbr1 inet static
    address 10.10.10.1/24 # IP dentro de esta interfaz.
    bridge-ports none
    bridge-stp off
    bridge-fd 0

    post-up   echo 1 &gt; /proc/sys/net/ipv4/ip_forward # Permite hacer port-forwarding para mandar puertos a VM.
    post-up iptables -t nat -A PREROUTING -i vmbr0 -p udp --dport 51820 -j DNAT --to 10.10.10.3:51820 # Ejemplo de mandar puerto 51820 UDP a VM.
    post-down iptables -t nat -D PREROUTING -i vmbr0 -p udp --dport 51820 -j DNAT --to 10.10.10.3:51820
    post-up   iptables -t nat -A POSTROUTING -s '10.10.10.0/24' -o vmbr0 -j MASQUERADE # Permite acceder a la red accediendo desde vmbr0
    post-down iptables -t nat -D POSTROUTING -s '10.10.10.0/24' -o vmbr0 -j MASQUERADE
    post-up   iptables -t nat -A POSTROUTING -s '10.10.11.0/24' -o vmbr0 -j MASQUERADE # Para la VPN
    post-down iptables -t nat -D POSTROUTING -s '10.10.11.0/24' -o vmbr0 -j MASQUERADE
    post-up iptables -t nat -A PREROUTING -i vmbr0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 10.10.10.4:80 # Manda el tr√°fico del 80 al balanceador de carga
    post-up iptables -t nat -A PREROUTING -i vmbr0 -p tcp -m tcp --dport 443 -j DNAT --to-destination 10.10.10.4:443 # Manda el tr√°fico del 443 al balanceador de carga.
</code></pre><p>Finalmente, ejecutamos <code>service networking restart</code> y tendremos una red virtual privada creada para nuestras m√°quinas virtuales.</p><h3 id=creando-template-con-debian-10-proxmox>Creando template con Debian 10 Proxmox.</h3><p>Ejecutamos el siguiente script para crear un template con Debian 10 con soporte para Cloud Init:</p><pre><code>wget https://cdimage.debian.org/cdimage/openstack/current/debian-10-openstack-amd64.qcow2

# Create a VM
qm create 9110 --name debian10-cloud --memory 2048 --net0 virtio,bridge=vmbr1

# Import the disk in qcow2 format (as unused disk)
qm importdisk 9110 debian-10-openstack-amd64.qcow2 local -format qcow2

# Attach the disk to the vm using VirtIO SCSI
qm set 9110 --scsihw virtio-scsi-pci --scsi0 /var/lib/vz/images/9110/vm-9110-disk-0.qcow2

# Important settings
qm set 9110 --ide2 local:cloudinit --boot c --bootdisk scsi0 --serial0 socket --vga serial0

# The initial disk is only 2GB, thus we make it larger
qm resize 9110 scsi0 +30G

# Using a  dhcp server on vmbr1 or use static IP
qm set 9110 --ipconfig0 ip=10.10.10.2/24,gw=10.10.10.1

# user authentication for 'debian' user (optional password)
qm set 9110 --sshkey ~/.ssh/id_rsa.pub

# check the cloud-init config
qm cloudinit dump 9110 user

# create tempalte and a linked clone
qm template 9110
</code></pre><p>En este punto, tendremos un template con Debian 10, listo para ser clonado en nuestras nuevas m√°quinas virtuales.</p><h3 id=creando-m√°quinas-con-terraform>Creando m√°quinas con Terraform.</h3><p>En la carpeta donde vayamos a escribir los ficheros de Terraform, creamos un fichero <code>versions.tf</code> con el siguiente contenido:</p><pre><code>terraform {
    required_providers {
        proxmox = {
        source  = &quot;Telmate/Proxmox&quot;
        version = &quot;&gt;=1.0.0&quot;
        }
    }
required_version = &quot;&gt;= 0.13&quot;
}
</code></pre><p>Este fichero, le dir√° a Terraform que plugins usar, a continuaci√≥n creamos el fichero <code>main.tf</code>:</p><pre><code>provider &quot;proxmox&quot; {
    pm_api_url      = &quot;https://&lt;ip publica&gt;:8006/api2/json&quot;
    pm_user         = &quot;root@pam&quot;
    pm_tls_insecure = true
}
</code></pre><p>Este bloque, te permitir√° conectarte a tu Proxmox, para generar m√°quinas f√°cilmente. Ejecutamos <code>terraform init</code> y ya podremos empezar a trabajar.</p><h3 id=vpn-wireguard-acceder-desde-fuera-a-la-red-virtual>VPN (Wireguard): Acceder desde fuera a la red virtual.</h3><p>Configuraci√≥n Terraform:
resource &ldquo;proxmox_vm_qemu&rdquo; &ldquo;vpn&rdquo; {
name = &ldquo;vpn&rdquo;</p><pre><code>    target_node = &quot;xxxx&quot;
    os_type     = &quot;cloud-init&quot;

    clone = &quot;debian10-cloud&quot;

    memory = 512
    cores  = &quot;1&quot;

    sshkeys = &quot;&lt;tu clave SSH&gt;&quot;

    ipconfig0 = &quot;ip=10.10.10.3/32,gw=10.10.10.1&quot; # Aqu√≠ configuramos la IP privada de nuestra VM

    bootdisk = &quot;scsi0&quot;

    disk {
        type    = &quot;scsi&quot;
        storage = &quot;local&quot;
        size    = &quot;35G&quot;
    }

    lifecycle {
        ignore_changes = [
        network,
        ]
    }
}
</code></pre><p>Ejecutamos <code>terraform apply</code> para que cree la m√°quina, y una vez que se haya creado la m√°quina, entraremos para instalar y configurar wireguard:</p><ol><li><p>Ejecutamos <code>sudo apt update</code></p></li><li><p>Ejecutamos <code>sudo apt upgrade</code></p></li><li><p>Activamos el repositorio de backports, que es donde se aloja wireguard: <code>sudo sh -c "echo 'deb http://deb.debian.org/debian buster-backports main contrib non-free' > /etc/apt/sources.list.d/buster-backports.list"</code></p></li><li><p>Volvemos a actualizar nuestros repositorios: <code>sudo apt update</code></p></li><li><p>Instalamos wireguard: <code>sudo apt install wireguard</code></p></li><li><p>Entramos en <code>/etc/wireguard/</code>; <code>cd /etc/wireguard/</code></p></li><li><p>Generamos las claves privadas y p√∫blicas del servidor: <code>umask 077; wg genkey | tee privatekey | wg pubkey > publickey</code></p></li><li><p>Creamos el fichero wg0.conf:</p><pre><code> [Interface]
 Address = 10.10.11.1/24 # IP de los clientes y servidor de la VPN
 ListenPort = 51820
 PrivateKey = &lt;contenido fichero /etc/wireguard/privatekey&gt;
 PostUp = iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE;  iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT # Permitimos a los clientes acceder a la red privada.
</code></pre></li><li><p>En nuestro ordenador local instalamos wireguard, y accedemos a <code>/etc/wireguard/</code> y seguidamente, ejecutamos <code>umask 077; wg genkey | tee privatekey | wg pubkey > publickey</code></p></li><li><p>Volvemos, al servidor y copiamos la clave p√∫blica del cliente, y creamos un peer de wireguard:</p><pre><code>[Peer]
PublicKey = &lt;Clave p√∫blica del cliente&gt;
AllowedIPs = 10.10.11.2/24  # IP del cliente
</code></pre></li><li><p>Iniciamos wireguard en la m√°quina virtual: <code>systemctl enable wg-quick@wg0 --now</code></p></li><li><p>En nuestro ordenador local, terminamos de configurar wireguard, creamos el fichero <code>/etc/wireguard/wg0.conf</code></p><pre><code>[Interface]
Address = 10.10.11.2/24 # IP del cliente
DNS = 8.8.8.8
PrivateKey = &lt;Private key de nuestra m√°quina&gt;

[Peer]
PublicKey = &lt;Public key del servidor&gt;
AllowedIPs = 10.10.10.0/24 # IPs que van a pasar por la VPN, en nuestro caso 10.10.10.0/24 porque son las de vmbr1
Endpoint = &lt;ip publica servidor&gt;:51820
PersistentKeepalive = 25
</code></pre></li><li><p>Iniciamos en local la VPN: <code>systemctl enable wg-quick@wg0 --now</code></p></li></ol><h3 id=otras-m√°quinas-necesarias>Otras m√°quinas necesarias</h3><p>Se crear√°n 4 m√°quinas virtuales m√°s:</p><ol><li>Balancer, una m√°quina con debian 10 con la IP 10.10.10.4, que ser√° un worker de de Kubernetes donde ejecutaremos simplemente el NGINX Ingress (1GB de RAM | 1 CPU)</li><li>2 rancher-nodes, donde desplegaremos etcd, controlplane y los pods del cl√∫ster. (2GB de RAM | 2 CPU)</li><li>Rancher, panel de administraci√≥n de K8s. (2GB de RAM | 1 CPU)</li></ol><h2 id=kubernetes-f√°cilmente-rancher>Kubernetes f√°cilmente: Rancher</h2><h3 id=instalando-rancher>Instalando Rancher</h3><p>Rancher puede instalarse directamente en un cl√∫ster existente de Kubernetes, podemos desplegarlo dentro de K3s, o simplemente ejecutarlo desde docker. En un entorno de producci√≥n <strong>no es recomendable</strong> instalar rancher directamente desde docker, a√∫n as√≠, para mi caso, que no es un entorno cr√≠tico, lo instalar√© directamente en docker para ahorrarme recursos:</p><ol><li>Creamos la m√°quina para rancher, que tendr√° la IP 10.10.10.5</li><li>Instalamos docker, <code>sudo apt update; sudo apt install docker.io</code></li><li>Ejecutamos e instalamos rancher: <code>docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher:latest</code></li></ol><p>Esperamos, un tiempo y podremos acceder al panel de rancher por primera vez:<figure><a href=/p/mi-nueva-infraestructura/rancher-setup.png data-size=890x815><img srcset="/p/mi-nueva-infraestructura/rancher-setup_hu64f117aa05da2354fa7e3699417ce779_56588_480x0_resize_box_2.png 480w, /p/mi-nueva-infraestructura/rancher-setup_hu64f117aa05da2354fa7e3699417ce779_56588_1024x0_resize_box_2.png 1024w" src=/p/mi-nueva-infraestructura/rancher-setup.png width=890 height=815 loading=lazy alt="Rancher setup"></a><figcaption>Rancher setup</figcaption></figure></p><p>Una vez terminada la configuraci√≥n inicial, veremos el listado de todos los cl√∫sters de K8s administrados desde rancher, en este momento, s√≥lo veremos uno <em>local</em>, que es el propio cl√∫ster de Rancher. Nuestra siguiente tarea ser√° crear un cl√∫ster de Kubernetes para las dos m√°quinas nuevas que hemos creado:</p><h3 id=creando-un-nuevo-cl√∫ster-de-kubernetes>Creando un nuevo cl√∫ster de Kubernetes.</h3><p>Desde la interfaz de rancher, hacemos click sobre <strong>Add cluster</strong>, y veremos la siguiente interfaz:<figure><a href=/p/mi-nueva-infraestructura/new-cluster.png data-size=1577x913><img srcset="/p/mi-nueva-infraestructura/new-cluster_hu8790b239e5a342f0a339c0cb9ff2a4c4_55338_480x0_resize_box_2.png 480w, /p/mi-nueva-infraestructura/new-cluster_hu8790b239e5a342f0a339c0cb9ff2a4c4_55338_1024x0_resize_box_2.png 1024w" src=/p/mi-nueva-infraestructura/new-cluster.png width=1577 height=913 loading=lazy alt="Nuevo cl√∫ster"></a><figcaption>Nuevo cl√∫ster</figcaption></figure>En mi caso, voy a lanzar un nuevo cl√∫ster en <em>Existing nodes</em>, pero si nuestra infraestructura est√° desplegada en otro proveedor, podemos tambi√©n desplegarla f√°cilmente desde rancher. En mi cl√∫ster, he a√±adido la siguiente configuraci√≥n:</p><ul><li>**Nombre: ** my-kube</li><li>**Network provider: **: calico</li></ul><p>Una vez rellenada esta configuraci√≥n, nos mostrar√° una pantalla con un comando que debemos ejecutar en las m√°quinas que queremos que formen parte del cl√∫ster. En un entorno de producci√≥n es recomendable instalar etcd, controlplane y worker por separado. Para mi caso particular, que es un entorno &ldquo;para mi&rdquo;, voy a instalar etcd, controlplane y worker en la misma m√°quina:</p><pre><code>sudo apt update
sudo apt install docker.io
sudo docker run -d --privileged --restart=unless-stopped --net=host -v /etc/kubernetes:/etc/kubernetes -v /var/run:/var/run rancher/rancher-agent:v2.5.5 --server https://10.10.10.5 --token xxxxx --ca-checksum xxxxx --etcd --controlplane --worker
</code></pre><p>A medida que ejecutamos este comando en todas las m√°quinas, veremos como nuestros nodos pasar√°n a formar parte del nuevo cl√∫ster de Kubernetes que hemos creado:<figure><a href=/p/mi-nueva-infraestructura/rancher-one-node.png data-size=1910x352><img srcset="/p/mi-nueva-infraestructura/rancher-one-node_hubb04ec1a2d5570d1f44bba2e911fa881_33217_480x0_resize_box_2.png 480w, /p/mi-nueva-infraestructura/rancher-one-node_hubb04ec1a2d5570d1f44bba2e911fa881_33217_1024x0_resize_box_2.png 1024w" src=/p/mi-nueva-infraestructura/rancher-one-node.png width=1910 height=352 loading=lazy alt="Nuevo cl√∫ster"></a><figcaption>Nuevo cl√∫ster</figcaption></figure></p><p>En este punto, nos toca tener paciencia y esperar a que los nodos terminen de desplegarse&mldr; Cuando terminen de desplegarse, veremos lo siguiente:<figure><a href=/p/mi-nueva-infraestructura/nodes-full.png data-size=541x365><img srcset="/p/mi-nueva-infraestructura/nodes-full_hu159f53746b901ddeaf47948e114f4ae1_19966_480x0_resize_box_2.png 480w, /p/mi-nueva-infraestructura/nodes-full_hu159f53746b901ddeaf47948e114f4ae1_19966_1024x0_resize_box_2.png 1024w" src=/p/mi-nueva-infraestructura/nodes-full.png width=541 height=365 loading=lazy alt="Nuevo cl√∫ster"></a><figcaption>Nuevo cl√∫ster</figcaption></figure></p><h3 id=primeras-configuraciones>Primeras configuraciones</h3><ol><li>Creamos un nuevo proyecto d√≥nde desplegaremos las aplicaciones de josecarlos.me, tungsteno.app y demo.tungsteno.app<ol><li>Buscamos en el men√∫ <code>Project/Namespaces</code></li><li>Le damos a <code>Add project</code></li><li>Creamos un nuevo proyecto, y accedemos al administrador del proyecto.</li></ol></li></ol><h3 id=desplegando-mis-aplicaciones>Desplegando mis aplicaciones</h3><p>En primer lugar, vamos a desplegar josecarlos.me. Accedemos a <em>workloads</em>, veremos la siguiente interfaz:<figure><a href=/p/mi-nueva-infraestructura/workloads.png data-size=1890x275><img srcset="/p/mi-nueva-infraestructura/workloads_hu18efcce590ec91e37ae54836ca996272_20671_480x0_resize_box_2.png 480w, /p/mi-nueva-infraestructura/workloads_hu18efcce590ec91e37ae54836ca996272_20671_1024x0_resize_box_2.png 1024w" src=/p/mi-nueva-infraestructura/workloads.png width=1890 height=275 loading=lazy alt="Nuevo cl√∫ster"></a><figcaption>Nuevo cl√∫ster</figcaption></figure></p><p>Hacemos click sobre <strong>Deploy</strong>, y desplegamos el pod con la imagen Docker de nuestra aplicaci√≥n:<figure><a href=/p/mi-nueva-infraestructura/hugo-deploy.png data-size=1900x853><img srcset="/p/mi-nueva-infraestructura/hugo-deploy_hu0eba43997d0f7a59e992adb6693a8038_65423_480x0_resize_box_2.png 480w, /p/mi-nueva-infraestructura/hugo-deploy_hu0eba43997d0f7a59e992adb6693a8038_65423_1024x0_resize_box_2.png 1024w" src=/p/mi-nueva-infraestructura/hugo-deploy.png width=1900 height=853 loading=lazy alt="Nuevo cl√∫ster"></a><figcaption>Nuevo cl√∫ster</figcaption></figure>.</p><p>Configuramos un balanceador de carga para mandar josecarlos.me hacia el pod creado anteriormente. Entramos en primer lugar sobre <em>load balancing</em>, seguidamente hacemos click sobre <strong>Add ingress</strong>:</p><p><figure><a href=/p/mi-nueva-infraestructura/josecarlos-ingress.png data-size=1905x920><img srcset="/p/mi-nueva-infraestructura/josecarlos-ingress_hufd0f34d862b9130692cad5fa6b894866_63207_480x0_resize_box_2.png 480w, /p/mi-nueva-infraestructura/josecarlos-ingress_hufd0f34d862b9130692cad5fa6b894866_63207_1024x0_resize_box_2.png 1024w" src=/p/mi-nueva-infraestructura/josecarlos-ingress.png width=1905 height=920 loading=lazy alt="Nuevo cl√∫ster"></a><figcaption>Nuevo cl√∫ster</figcaption></figure>.</p><p>Repitiendo el proceso para tungsteno.app, habremos terminado.</p><h2 id=conclusiones>Conclusiones</h2></section><footer class=article-footer><section class=article-tags><a href=/tags/ops/>ops</a>
<a href=/tags/proxmox/>proxmox</a>
<a href=/tags/kubernetes/>kubernetes</a>
<a href=/tags/private-network/>private-network</a>
<a href=/tags/wireguard/>wireguard</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-contents--wrapper><h2 class=section-title>Contenido relacionado</h2><div class=related-contents><div class="flex article-list--tile"><article class=has-image><a href=/p/varnish-mostrar-la-cache-cuando-se-caiga-el-backend/><div class=article-image><img src=/p/varnish-mostrar-la-cache-cuando-se-caiga-el-backend/covevr_hu12125da067c48c84553b832ac79c99a2_499757_250x150_fill_q75_box_smart1.jpeg width=250 height=150 loading=lazy data-key=varnish-mostrar-la-cache-cuando-se-caiga-el-backend data-hash="md5-L4nN+sc26hYeSP/kp33HfA=="></div><div class=article-details><h2 class=article-title>Varnish: ¬øC√≥mo mantengo un sitio siempre online y evitos peticiones extras al backend?</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"el-blog-de-j-carlos"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><footer class=site-footer><section class=copyright>&copy; 2021 El blog de J. Carlos</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=1.0.5>Stack</a></b> designed by
<a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true style=display:none><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const customFont=document.createElement('link');customFont.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";customFont.type="text/css";customFont.rel="stylesheet";document.head.appendChild(customFont);}());</script><link rel=stylesheet href=/css/highlight/light.min.css media="(prefers-color-scheme: light)"><link rel=stylesheet href=/css/highlight/dark.min.css media="(prefers-color-scheme: dark)"></body></html>