[{"content":"Hasta el momento, tenía contratado 4 VPS con una capacidad bastante limitada dónde he desplegado mis dos principales proyectos personales, tungsteno.app y josecarlos.me. En estos servidores virtuales tenía desplegado un clúster de Kubernetes con un total de 4vCPU y 8GB de RAM.\nEn las últimas semanas, he estado atento a las ofertas de servidores dedicados de Kimsufi, una empresa que alquila servidores dedicados antiguos a un precio reducido, y he conseguido contratar el servidor KS-11, por tanto, ahora tengo una CPU de 8 hilos y 16 GB de RAM, y aunque es lento, también dispongo de 2TB de disco HDD. Estas condiciones me ayudaron a decidirme a montar un Proxmox, con distintas máquinas virtuales montadas con Terraform, una red privada, un entorno propio de laboratorio y muchas otras opciones para probar.\nTabla de contenido  Proxmox  Instalación Configurando una red privada para todas las máquinas virtuales Creando template con Debian 10 Proxmox. Creando máquinas con Terraform. VPN (Wireguard): Acceder desde fuera a la red virtual. Otras máquinas necesarias   Kubernetes fácilmente: Rancher  Instalando Rancher Creando un nuevo clúster de Kubernetes. Primeras configuraciones Desplegando mis aplicaciones   Conclusiones     Proxmox Proxmox Virtual Environment, o Proxmox VE, entorno de virtualización de servidores de código abierto. Está en distribuciones GNU/Linux basadas en Debian con una versión modificada del Kernel RHEL y permite el despliegue y la gestión de máquinas virtuales y contenedores. Proxmox VE incluye una consola Web y herramientas de línea de comandos, y proporciona una API REST para herramientas de terceros. Dos tipos de virtualización son compatibles: los contenedores basados con LXC (a partir de la versión 4.0 reemplaza OpenVZ, utilizado en la versión 3.4, incluido3​), y la virtualización con KVM. Viene con un instalador e incluye un sitio Web basado en la interfaz de administración.\nInstalación Desde Kimsufi, o OVH tienes la posibilidad de instalar directamente un dedicado con la imagen de Proxmox. Si tienes otro proveedor, que no ofrece la opción de instalarlo desde las opciones de \u0026ldquo;despliegue\u0026rdquo;, siempre puedes ver las guías de instalación en la Wiki de Proxmox.\nConfigurando una red privada para todas las máquinas virtuales En mi proveedor del dedicado, sólo ofrecen la posibilidad de tener una IP pública por dedicado, así que he tenido que configurar una red privada, y con configuraciones de port forwarding para redirigir desde la IP pública, a las distintas máquinas virtuales según el puerto.\nPor defecto, mi servidor dedicado venía con estas interfaces de red:\nroot@xxxx:~# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: enp1s0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast master vmbr0 state UP group default qlen 1000 link/ether 00:25:90:76:dd:00 brd ff:ff:ff:ff:ff:ff 3: enp2s0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 00:25:90:76:dd:01 brd ff:ff:ff:ff:ff:ff 4: vmbr0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 00:25:90:76:dd:00 brd ff:ff:ff:ff:ff:ff inet \u0026lt;ip publica\u0026gt;/24 brd \u0026lt;gateway\u0026gt;.255 scope global dynamic vmbr0 valid_lft 81716sec preferred_lft 81716sec inet6 \u0026lt;ip publica\u0026gt;/64 scope link valid_lft forever preferred_lft forever  Con la siguiente configuración:\nauto lo iface lo inet loopback iface enp1s0 inet manual iface enp2s0 inet manual auto vmbr0 iface vmbr0 inet dhcp bridge-ports enp1s0 bridge-stp off bridge-fd 0 auto vmbr1  Nuestro objetivo es crear un puente virtual en nuestro dedicado, dónde desplegaremos las IPs de nuestras máquinas virtuales. Para ello, editamos el fichero /etc/network/interfaces, y añadimos al final:\nauto vmbr1 # Nombre de la interfaz iface vmbr1 inet static address 10.10.10.1/24 # IP dentro de esta interfaz. bridge-ports none bridge-stp off bridge-fd 0 post-up echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward # Permite hacer port-forwarding para mandar puertos a VM. post-up iptables -t nat -A PREROUTING -i vmbr0 -p udp --dport 51820 -j DNAT --to 10.10.10.3:51820 # Ejemplo de mandar puerto 51820 UDP a VM. post-down iptables -t nat -D PREROUTING -i vmbr0 -p udp --dport 51820 -j DNAT --to 10.10.10.3:51820 post-up iptables -t nat -A POSTROUTING -s '10.10.10.0/24' -o vmbr0 -j MASQUERADE # Permite acceder a la red accediendo desde vmbr0 post-down iptables -t nat -D POSTROUTING -s '10.10.10.0/24' -o vmbr0 -j MASQUERADE post-up iptables -t nat -A POSTROUTING -s '10.10.11.0/24' -o vmbr0 -j MASQUERADE # Para la VPN post-down iptables -t nat -D POSTROUTING -s '10.10.11.0/24' -o vmbr0 -j MASQUERADE post-up iptables -t nat -A PREROUTING -i vmbr0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 10.10.10.4:80 # Manda el tráfico del 80 al balanceador de carga post-up iptables -t nat -A PREROUTING -i vmbr0 -p tcp -m tcp --dport 443 -j DNAT --to-destination 10.10.10.4:443 # Manda el tráfico del 443 al balanceador de carga.  Finalmente, ejecutamos service networking restart y tendremos una red virtual privada creada para nuestras máquinas virtuales.\nCreando template con Debian 10 Proxmox. Ejecutamos el siguiente script para crear un template con Debian 10 con soporte para Cloud Init:\nwget https://cdimage.debian.org/cdimage/openstack/current/debian-10-openstack-amd64.qcow2 # Create a VM qm create 9110 --name debian10-cloud --memory 2048 --net0 virtio,bridge=vmbr1 # Import the disk in qcow2 format (as unused disk) qm importdisk 9110 debian-10-openstack-amd64.qcow2 local -format qcow2 # Attach the disk to the vm using VirtIO SCSI qm set 9110 --scsihw virtio-scsi-pci --scsi0 /var/lib/vz/images/9110/vm-9110-disk-0.qcow2 # Important settings qm set 9110 --ide2 local:cloudinit --boot c --bootdisk scsi0 --serial0 socket --vga serial0 # The initial disk is only 2GB, thus we make it larger qm resize 9110 scsi0 +30G # Using a dhcp server on vmbr1 or use static IP qm set 9110 --ipconfig0 ip=10.10.10.2/24,gw=10.10.10.1 # user authentication for 'debian' user (optional password) qm set 9110 --sshkey ~/.ssh/id_rsa.pub # check the cloud-init config qm cloudinit dump 9110 user # create tempalte and a linked clone qm template 9110  En este punto, tendremos un template con Debian 10, listo para ser clonado en nuestras nuevas máquinas virtuales.\nCreando máquinas con Terraform. En la carpeta donde vayamos a escribir los ficheros de Terraform, creamos un fichero versions.tf con el siguiente contenido:\nterraform { required_providers { proxmox = { source = \u0026quot;Telmate/Proxmox\u0026quot; version = \u0026quot;\u0026gt;=1.0.0\u0026quot; } } required_version = \u0026quot;\u0026gt;= 0.13\u0026quot; }  Este fichero, le dirá a Terraform que plugins usar, a continuación creamos el fichero main.tf:\nprovider \u0026quot;proxmox\u0026quot; { pm_api_url = \u0026quot;https://\u0026lt;ip publica\u0026gt;:8006/api2/json\u0026quot; pm_user = \u0026quot;root@pam\u0026quot; pm_tls_insecure = true }  Este bloque, te permitirá conectarte a tu Proxmox, para generar máquinas fácilmente. Ejecutamos terraform init y ya podremos empezar a trabajar.\nVPN (Wireguard): Acceder desde fuera a la red virtual. Configuración Terraform: resource \u0026ldquo;proxmox_vm_qemu\u0026rdquo; \u0026ldquo;vpn\u0026rdquo; { name = \u0026ldquo;vpn\u0026rdquo;\n target_node = \u0026quot;xxxx\u0026quot; os_type = \u0026quot;cloud-init\u0026quot; clone = \u0026quot;debian10-cloud\u0026quot; memory = 512 cores = \u0026quot;1\u0026quot; sshkeys = \u0026quot;\u0026lt;tu clave SSH\u0026gt;\u0026quot; ipconfig0 = \u0026quot;ip=10.10.10.3/32,gw=10.10.10.1\u0026quot; # Aquí configuramos la IP privada de nuestra VM bootdisk = \u0026quot;scsi0\u0026quot; disk { type = \u0026quot;scsi\u0026quot; storage = \u0026quot;local\u0026quot; size = \u0026quot;35G\u0026quot; } lifecycle { ignore_changes = [ network, ] } }  Ejecutamos terraform apply para que cree la máquina, y una vez que se haya creado la máquina, entraremos para instalar y configurar wireguard:\n  Ejecutamos sudo apt update\n  Ejecutamos sudo apt upgrade\n  Activamos el repositorio de backports, que es donde se aloja wireguard: sudo sh -c \u0026quot;echo 'deb http://deb.debian.org/debian buster-backports main contrib non-free' \u0026gt; /etc/apt/sources.list.d/buster-backports.list\u0026quot;\n  Volvemos a actualizar nuestros repositorios: sudo apt update\n  Instalamos wireguard: sudo apt install wireguard\n  Entramos en /etc/wireguard/; cd /etc/wireguard/\n  Generamos las claves privadas y públicas del servidor: umask 077; wg genkey | tee privatekey | wg pubkey \u0026gt; publickey\n  Creamos el fichero wg0.conf:\n [Interface] Address = 10.10.11.1/24 # IP de los clientes y servidor de la VPN ListenPort = 51820 PrivateKey = \u0026lt;contenido fichero /etc/wireguard/privatekey\u0026gt; PostUp = iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE; iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT # Permitimos a los clientes acceder a la red privada.    En nuestro ordenador local instalamos wireguard, y accedemos a /etc/wireguard/ y seguidamente, ejecutamos umask 077; wg genkey | tee privatekey | wg pubkey \u0026gt; publickey\n  Volvemos, al servidor y copiamos la clave pública del cliente, y creamos un peer de wireguard:\n[Peer] PublicKey = \u0026lt;Clave pública del cliente\u0026gt; AllowedIPs = 10.10.11.2/24 # IP del cliente    Iniciamos wireguard en la máquina virtual: systemctl enable wg-quick@wg0 --now\n  En nuestro ordenador local, terminamos de configurar wireguard, creamos el fichero /etc/wireguard/wg0.conf\n[Interface] Address = 10.10.11.2/24 # IP del cliente DNS = 8.8.8.8 PrivateKey = \u0026lt;Private key de nuestra máquina\u0026gt; [Peer] PublicKey = \u0026lt;Public key del servidor\u0026gt; AllowedIPs = 10.10.10.0/24 # IPs que van a pasar por la VPN, en nuestro caso 10.10.10.0/24 porque son las de vmbr1 Endpoint = \u0026lt;ip publica servidor\u0026gt;:51820 PersistentKeepalive = 25    Iniciamos en local la VPN: systemctl enable wg-quick@wg0 --now\n  Otras máquinas necesarias Se crearán 4 máquinas virtuales más:\n Balancer, una máquina con debian 10 con la IP 10.10.10.4, que será un worker de de Kubernetes donde ejecutaremos simplemente el NGINX Ingress (1GB de RAM | 1 CPU) 2 rancher-nodes, donde desplegaremos etcd, controlplane y los pods del clúster. (2GB de RAM | 2 CPU) Rancher, panel de administración de K8s. (2GB de RAM | 1 CPU)  Kubernetes fácilmente: Rancher Instalando Rancher Rancher puede instalarse directamente en un clúster existente de Kubernetes, podemos desplegarlo dentro de K3s, o simplemente ejecutarlo desde docker. En un entorno de producción no es recomendable instalar rancher directamente desde docker, aún así, para mi caso, que no es un entorno crítico, lo instalaré directamente en docker para ahorrarme recursos:\n Creamos la máquina para rancher, que tendrá la IP 10.10.10.5 Instalamos docker, sudo apt update; sudo apt install docker.io Ejecutamos e instalamos rancher: docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher:latest  Esperamos, un tiempo y podremos acceder al panel de rancher por primera vez:   Rancher setup \nUna vez terminada la configuración inicial, veremos el listado de todos los clústers de K8s administrados desde rancher, en este momento, sólo veremos uno local, que es el propio clúster de Rancher. Nuestra siguiente tarea será crear un clúster de Kubernetes para las dos máquinas nuevas que hemos creado:\nCreando un nuevo clúster de Kubernetes. Desde la interfaz de rancher, hacemos click sobre Add cluster, y veremos la siguiente interfaz:   Nuevo clúster  En mi caso, voy a lanzar un nuevo clúster en Existing nodes, pero si nuestra infraestructura está desplegada en otro proveedor, podemos también desplegarla fácilmente desde rancher. En mi clúster, he añadido la siguiente configuración:\n **Nombre: ** my-kube **Network provider: **: calico  Una vez rellenada esta configuración, nos mostrará una pantalla con un comando que debemos ejecutar en las máquinas que queremos que formen parte del clúster. En un entorno de producción es recomendable instalar etcd, controlplane y worker por separado. Para mi caso particular, que es un entorno \u0026ldquo;para mi\u0026rdquo;, voy a instalar etcd, controlplane y worker en la misma máquina:\nsudo apt update sudo apt install docker.io sudo docker run -d --privileged --restart=unless-stopped --net=host -v /etc/kubernetes:/etc/kubernetes -v /var/run:/var/run rancher/rancher-agent:v2.5.5 --server https://10.10.10.5 --token xxxxx --ca-checksum xxxxx --etcd --controlplane --worker  A medida que ejecutamos este comando en todas las máquinas, veremos como nuestros nodos pasarán a formar parte del nuevo clúster de Kubernetes que hemos creado:   Nuevo clúster \nEn este punto, nos toca tener paciencia y esperar a que los nodos terminen de desplegarse\u0026hellip; Cuando terminen de desplegarse, veremos lo siguiente:   Nuevo clúster \nPrimeras configuraciones  Creamos un nuevo proyecto dónde desplegaremos las aplicaciones de josecarlos.me, tungsteno.app y demo.tungsteno.app  Buscamos en el menú Project/Namespaces Le damos a Add project Creamos un nuevo proyecto, y accedemos al administrador del proyecto.    Desplegando mis aplicaciones En primer lugar, vamos a desplegar josecarlos.me. Accedemos a workloads, veremos la siguiente interfaz:   Nuevo clúster \nHacemos click sobre Deploy, y desplegamos el pod con la imagen Docker de nuestra aplicación:   Nuevo clúster .\nConfiguramos un balanceador de carga para mandar josecarlos.me hacia el pod creado anteriormente. Entramos en primer lugar sobre load balancing, seguidamente hacemos click sobre Add ingress:\n  Nuevo clúster .\nRepitiendo el proceso para tungsteno.app, habremos terminado.\nConclusiones ","description":"","image":"cover.jpeg","permalink":"https://josecarlos.me/p/mi-nueva-infraestructura/","subtitle":null,"tags":["ops","proxmox","kubernetes","private-network","wireguard"],"title":"Mi nueva infraestructura. Proxmox + Private Network + Terraform + VPN + Kubernetes (Rancher)"},{"content":"","description":null,"image":"ia.jpeg","permalink":"https://josecarlos.me/categories/ia/","subtitle":null,"tags":null,"title":"Inteligencia artifical"},{"content":"","description":null,"image":"ram.jpeg","permalink":"https://josecarlos.me/categories/ops/","subtitle":null,"tags":null,"title":"Operaciones"},{"content":"¿Qué es Varnish? Varnish es un sistema de cache que se utiliza principalmente para cubrir las siguientes necesidades:\n Cachear nuestros sitios webs para reducir la carga del backend. Acelerar la carga de estáticos para cargarlo directamente en la RAM. \u0026hellip;  Varnish tiene una documentación bastante completa que es pública para todo el mundo y podemos consultar directamente en:\n https://varnish-cache.org/docs/6.5/  Una de las configuraciones más interesantes de Varnish nos permite configurar cuanto tiempo debe de estar un objeto en la cache.\nConfiguración en varnish de tiempos de cache En la documentación de varnish podemos encontrar como configurar los tiempos que se mantendrá un objeto en la cache.\nEn este caso, nos vamos a centrar en beresp.ttl y beresp.grace\nberesp.ttl Esta configuración nos permite configurar cuanto tiempo debe de estar un objeto en la cache. Cuando pase este tiempo, el objeto dejará de servirse desde la cache (Si no tenemos configurado beresp.grace). Por ejemplo, si configuramos set beresp.ttl=1h, cuando pase una hora, el fichero se volverá a pedir al backend.\nberesp.grace Esta configuración nos permite configurar un periodo de gracia que nos permitirá seguir mostrando a los usuarios versiones caducadas de la cache, mientras que varnish consulta al backend por una versión actualizada.\nVentajas de usar beresp.grace Una vez introducidas estas dos configuraciones, se van a mostrar dos ejemplos para que el lector entienda la necesidad del uso de beresp.grace.\nSupongamos que tenemos un fichero HTML fichero.html con un TTL de 1h y beresp.grace de 24h.\nEjemplo 1: Mucho tráfico  Supongamos que fichero.html no se encuentra en la cache actualmente, y que un cliente accede a misitio.com/fichero.html, en este caso,** Varnish irá al backend y pedirá la versión más nueva de fichero.html**, y **la guardará en cache.** Si otro cliente accede en la próxima hora a misitio.com/fichero.html, recibirá la versión de fichero.html que tiene varnish guardada en la cache. Supongamos que cuando caduca el fichero de la cache, entran 100 usuarios simultaneos en nuestro sitio web. Si no tenemos configurado el beresp.grace, a nuestro backend llegarían 100 peticiones, ya que la cache ha caducado. Sin embargo, si tenemos configurado el beresp.grace** los 100 clientes recibirán la versión que esta en cache de fichero.html**, y **seguidamente irá al backend y tratará de encontrar una versión actualizada de fichero.html**, pero en este caso, **sólo se hará una petición al backend**, ya que al estar dentro del período de gracia. **Cuando el backend responda a Varnish, Varnish guardará esta respuesta como la cache más nueva.** Finalmente, cuando acceda un usuario nuevo, Varnish mandará el nuevo fichero.html que ha guardado en la cache.  Ejemplo 2: Sitio online 24/7  Supongamos que fichero.html no se encuentra en la cache actualmente, y que un cliente accede a misitio.com/fichero.html, en este caso,** Varnish irá al backend y pedirá la versión más nueva de fichero.html**, y **la guardará en cache.** Supongamos que después de que se haya cargado en cache, se cae nuestro backend. Debido a que tenemos configurado un periodo de gracia de 24h, Varnish mostrará la versión que tiene en cache durante 24h, y tratará de actualizar la cache en segundo plano, cuando el sitio esté disponible. Los usuarios podrán seguir viendo la web online, ya que Varnish está sirviendola. Supongamos que el backend vuelve a estar activo a las 12h, Varnish se conectará al backend, y automáticamente refrescará la cache con las versión actualizada de fichero.html  ","description":"","image":"covevr.jpeg","permalink":"https://josecarlos.me/p/varnish-mostrar-la-cache-cuando-se-caiga-el-backend/","subtitle":null,"tags":["ops","performance","varnish"],"title":"Varnish: ¿Cómo mantengo un sitio siempre online y evitos peticiones extras al backend?"},{"content":"Un poco sobre mi ¡Hola, mundo! Bienvenid@ a mi página personal, ya que estás por aquí, permíteme que te cuente un poco sobre mi, y un poco sobre el blog 😁\nSobre mi Me llamo José Carlos, y en el momento que estoy escribiendo esta entrada tengo 25 años. Estoy graduado en Matemáticas, y soy un apasionado de la informática general.\nDesde que era bastante pequeño me ha gustado trastear, aprender y romper ordenadores. Esto hizo que desde muy temprana edad mostrase interés por la programación. Tuve mi primer ordenador con apenas 6 años 👶, y con apenas 9 años la programación👨‍💻 me empezó a despertar curiosidad. Junto a un amigo del colegio empezamos a crear páginas webs estáticas gracias a servicios como Palimpalem. Cuando las páginas estáticas se me empezaron a quedar cortas, empecé a trastear con PHP y comencé a añadir un poco de interactividad a mis antiguas páginas estáticas gracias a servicios como MiArroba, que eran gratuitos y antes no me podía permitir 😭.\nMás adelante, empecé a explorar otro mundo bastante completo como es el de las CMS, mis primeros pasos fueron con Joomla!, y me ayudó para a crear una página, aún se puede encontrar en web.archive.org una copia de lo que fue mi primera web con Joomla! y se puede visitar aquí\nA la par de estas aventuras, comenzó unas de mis experiencias más fructiferas en el mundo de internet gracias a Kekomundo, un foro donde se desarrollaban servidores para copias de juegos online. En este mundo me di a conocer con varios proyectos, que muchos nostálgicos conocerán, y me hizo estar relacionado muchos años con Habbo Hotel.\nDe esta relación con Habbo Hotel, se desató mi pasión por la seguridad informática y por las matemáticas, y creo que fue el momento donde realmente me di cuenta que tenía que aprender más matemáticas para complementar mi formación que había desarrollado años atrás gracias a la curiosiad. En esta época encontré una serie de exploits dentro del cliente de Habbo Hotel que permitían hacer un Man-in-the-middle, debido a los problemas que existían en la implementación del cliente, en la librería Diffie-Hellman y más adelante usando tećnicas de detección de patrones buscando en la memoria RAM.\n  NovoFatum \nDespués de unos años muy divertidos y fructíferos, abandoné por completo este mundo para dedicarme plenamente al desarrollo de software libre, mis estudios y mi trabajo.\nCuando estaba en tercero de carrera, empecé a trabajar como desarrollador de software, donde también realizaba, operaciones y tareas de monitorización. Fueron 3 años muy fructifero, y más allá de que fuera mi primera experiencia profesional, me sirvió para aprender muchísimo del mundo Linux y me ayudó para desarrollar mi creatividad.\nA día, de hoy estoy empezando una nueva aventura laboral, y estoy trabajando en un proyecto de software libre que se llama Tungsteno, que trata de crear una alternativa libre para el Wolfram Mathematica. 😁\n","description":"📏 + 🔬 + 👨‍💻 + 🚴 + 🐧 + ☁️ = ❤️","image":"history.jpeg","permalink":"https://josecarlos.me/sobre-mi/","subtitle":null,"tags":null,"title":"Sobre mi"},{"content":"Cuando nos hablan de inteligencia artificial, nos asustamos y pensamos en primera instancia que estos conocimientos están lejos de la mano de los mortales.\nEn estas entradas voy a tratar de introducir de manera intuitiva los conceptos básicos del machine learning y presentar algunas implementaciones y aplicaciones, con el objetivo de aprender yo mismo, y que otra gente aprenda.\nEn este artículo tratamos uno de los modelos más básicos, la regresión lineal.\nPhoto by Drew Beamer/ UnsplashPredicciones básicas Supongamos que nos vamos a mudar a Boston, y estamos observando la relación entre el número de habitaciones y el precio de las viviendas.\nRecopilación de datos Anotamos en una tabla los valores que hemos observado:\n   Precio vivienda Nº de habitaciones     24.0 6.575   21.6 6.421   34.7 7.185   33.4 6.998   36.2 7.147   28.7 6.43   22.9 6.012   27.1 6.172   16.5 5.631   18.9 6.004    Un primer acercamiento que podemos hacer es dibujar una nube de puntos donde el eje de las X corresponda al número medio de habitaciones, y el eje de las Y corresponda al precio medio de la vivienda.\n  Una primera opción para resumir estos datos, es dibujar una recta que pase cerca de todos los datos, pero, ¿Cómo podemos hacerlo? ¿Podemos tantear la solución?\nParece que tratar de solucionar este problema por tanteo, no es factible, tratemos de buscar una solución aplicando las matemáticas.\nRecta de regresión lineal Queremos calcular una recta que minimice los errores entre todos los puntos Si calculamos la media de estos errores y los elevamos al cuadrado, obtenemos lo que se denomina error cuadrático medio, y la recta que cumple esta propiedad se denomina recta de regresión lineal.\nFórmulas para el cálculo de hiperplanos de regresión Si $X$ es la matriz de variables con una columna de $1$ en la primera columna, e $Y$ son los datos que tenemos y queremos predecir. Si observamos el caso de las viviendas en Boston, la matrix $X$ tendría dos columnas, una sólo con 1, y otra con la media de número de habitaciones, por otro lado, la $Y$ serían los precios de las viviendas.\nEntonces, el hiperplano $Y_e=\\beta X$ (O recta en $\\mathbb{R}^2$) tiene las siguientes componentes: $$ \\beta = (X^T X)^{-1} X^T Y $$\nDado que la primera columna de $X$ está compuesta por 1, el hiperplano vendrá definido por: $$ Y_e = \\beta_1 X + \\beta_0 $$ Donde $\\beta_i$ son las componentes del vector $\\beta$\nPrediciendo valores Si volvemos a nuestro caso especifico, vamos a calcular los valores $\\beta$ y $\\alpha$.\nNuestra matrices $X$ e $Y$, vienen definidas de la siguiente forma:\n$$ X=\\left(\\begin{matrix} 1 \u0026amp; 6.575 \\\n1 \u0026amp; 6.421 \\\n1 \u0026amp; 7.185 \\\n1 \u0026amp; 6.998 \\\n1 \u0026amp; 7.147 \\\n1 \u0026amp; 6.43 \\\n1 \u0026amp; 6.012 \\\n1 \u0026amp; 6.172 \\\n1 \u0026amp; 5.631 \\\n1 \u0026amp; 6.004 \\end{matrix}\\right), Y=\\left(\\begin{matrix} 24.0 \\\n21.6 \\\n34.7 \\\n33.4 \\\n36.2 \\\n28.7 \\\n22.9 \\\n27.1 \\\n16.5 \\\n18.9 \\end{matrix}\\right) $$\nPor tanto, $$\\beta=(-49.98256497, 11.82850406)$$ De donde, $$ y_e=x b_1 + b_0 $$\nPodemos pintar la recta con los gráficos para ver como se ajusta la recta: Supongamos ahora, que queremos calcular el precio estimado de una vivienda de 8 habitaciones, ahora simplemente deberíamos sustiuir en nuestra recta otros valores, y tendríamos: $$ y_e = 8 \\beta_1 + \\beta_0 = 44 $$\nPor lo cual, predecimos que valor de una vivienda de 8 habitaciones, tendrá un precio aproximadamente de 44k$\nPhoto by Hernan Lucio/ UnsplashCálculo de recta de regresión lineal Python Para este ejemplo utilizaremos la librería de cálculo científico numpy, se puede encontrar el ejemplo aquí:\n Ejemplo básico con Numpy Usando funciones ya existentes para calcular la recta de regresión  Limitaciones En el ejemplo específico de los precios de las viviendas en Boston según el número de habitaciones, se puede observar que los datos están más o menos cercanos a la recta de regresión que hemos calculado, y que la nube de puntos se \u0026ldquo;asemeja\u0026rdquo; a una recta. Sin embargo, esto no es siempre así. Podría ocurrir que nuestros datos estén sumamente dispersos, y que nos fuese imposible encontrar una recta de regresión donde el error mínimo sea demasiado grande.\nEs por eso, que se verán otros modelos más complejos que tratan de solucionar esto.\nAplicaciones Como hemos observado, estos modelos son muy básicos y presentan limitaciones, sin embargo son bastante potentes en ciertas situaciones para predecir comportamientos.\nPor ejemplo, podemos usar este modelo para predecir métricas en bases de datos temporales como Prometheus\nPrediciendo el futuro con Prometheus Prometheus incluye dos funciones interesante en este sentido predict_linear que predice el valor de una serie temporal en el futuro usando regresión lineal.\nEsta función nos puede servir para tantear el valor que tendrá una métrica en el futuro. Por ejemplo, si tenemos una métrica que cuenta la cantidad de usuarios conectados durante una campaña, podremos saber cuantos usuarios habrá dentro de un periodo de tiempo.\nPor otro lado, tenemos la función deriv, que nos devuelve la pendiente de la recta de regresión lineal.\nEsta pendiente nos permite calcular la velocidad con la que se está moviendo nuestra serie temporal y hacia que dirección. Por ejemplo, si tenemos una métrica que cubre el porcentaje de disco duro libre, y hacemos su derivada en los últimos 30 minutos, y nos da un valor negativo, podremos saber que se están escribiendo ficheros en el disco, además, dado que la pendiente de la recta modela la velocidad de crecimiento (o decrecimiento) de nuestros datos, podremos sacar conclusiones de cuando pasará algo. Photo by Luke Chesser/ UnsplashFuente / Enlaces de interés https://en.wikipedia.org/wiki/Linear_regression\nhttps://docs.scipy.org/doc/numpy/reference/routines.linalg.html\nhttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\nhttps://docs.scipy.org/doc/numpy/index.html\nhttps://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html\n  ","description":"","image":"cover.jpeg","permalink":"https://josecarlos.me/p/ia-1-introduccion/","subtitle":null,"tags":["ia","python","tensorflow"],"title":"Inteligencia Artificial: #1 Introducción, rectas de regresión"},{"content":"","description":null,"image":null,"permalink":"https://josecarlos.me/archives/","subtitle":null,"tags":null,"title":"Archives"}]