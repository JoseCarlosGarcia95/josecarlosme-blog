[{"content":"Hasta el momento, ten√≠a contratado 4 VPS con una capacidad bastante limitada d√≥nde he desplegado mis dos principales proyectos personales, tungsteno.app y josecarlos.me. En estos servidores virtuales ten√≠a desplegado un cl√∫ster de Kubernetes con un total de 4vCPU y 8GB de RAM.\nEn las √∫ltimas semanas, he estado atento a las ofertas de servidores dedicados de Kimsufi, una empresa que alquila servidores dedicados antiguos a un precio reducido, y he conseguido contratar el servidor KS-11, por tanto, ahora tengo una CPU de 8 hilos y 16 GB de RAM, y aunque es lento, tambi√©n dispongo de 2TB de disco HDD. Estas condiciones me ayudaron a decidirme a montar un Proxmox, con distintas m√°quinas virtuales montadas con Terraform, una red privada, un entorno propio de laboratorio y muchas otras opciones para probar.\nTabla de contenido  Proxmox  Instalaci√≥n Configurando una red privada para todas las m√°quinas virtuales Creando template con Debian 10 Proxmox. Creando m√°quinas con Terraform. VPN (Wireguard): Acceder desde fuera a la red virtual. Otras m√°quinas necesarias   Kubernetes f√°cilmente: Rancher  Instalando Rancher Creando un nuevo cl√∫ster de Kubernetes. Primeras configuraciones Desplegando mis aplicaciones   Conclusiones     Proxmox Proxmox Virtual Environment, o Proxmox VE, entorno de virtualizaci√≥n de servidores de c√≥digo abierto. Est√° en distribuciones GNU/Linux basadas en Debian con una versi√≥n modificada del Kernel RHEL y permite el despliegue y la gesti√≥n de m√°quinas virtuales y contenedores. Proxmox VE incluye una consola Web y herramientas de l√≠nea de comandos, y proporciona una API REST para herramientas de terceros. Dos tipos de virtualizaci√≥n son compatibles: los contenedores basados con LXC (a partir de la versi√≥n 4.0 reemplaza OpenVZ, utilizado en la versi√≥n 3.4, incluido3‚Äã), y la virtualizaci√≥n con KVM. Viene con un instalador e incluye un sitio Web basado en la interfaz de administraci√≥n.\nInstalaci√≥n Desde Kimsufi, o OVH tienes la posibilidad de instalar directamente un dedicado con la imagen de Proxmox. Si tienes otro proveedor, que no ofrece la opci√≥n de instalarlo desde las opciones de \u0026ldquo;despliegue\u0026rdquo;, siempre puedes ver las gu√≠as de instalaci√≥n en la Wiki de Proxmox.\nConfigurando una red privada para todas las m√°quinas virtuales En mi proveedor del dedicado, s√≥lo ofrecen la posibilidad de tener una IP p√∫blica por dedicado, as√≠ que he tenido que configurar una red privada, y con configuraciones de port forwarding para redirigir desde la IP p√∫blica, a las distintas m√°quinas virtuales seg√∫n el puerto.\nPor defecto, mi servidor dedicado ven√≠a con estas interfaces de red:\nroot@xxxx:~# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: enp1s0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast master vmbr0 state UP group default qlen 1000 link/ether 00:25:90:76:dd:00 brd ff:ff:ff:ff:ff:ff 3: enp2s0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 00:25:90:76:dd:01 brd ff:ff:ff:ff:ff:ff 4: vmbr0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 00:25:90:76:dd:00 brd ff:ff:ff:ff:ff:ff inet \u0026lt;ip publica\u0026gt;/24 brd \u0026lt;gateway\u0026gt;.255 scope global dynamic vmbr0 valid_lft 81716sec preferred_lft 81716sec inet6 \u0026lt;ip publica\u0026gt;/64 scope link valid_lft forever preferred_lft forever  Con la siguiente configuraci√≥n:\nauto lo iface lo inet loopback iface enp1s0 inet manual iface enp2s0 inet manual auto vmbr0 iface vmbr0 inet dhcp bridge-ports enp1s0 bridge-stp off bridge-fd 0 auto vmbr1  Nuestro objetivo es crear un puente virtual en nuestro dedicado, d√≥nde desplegaremos las IPs de nuestras m√°quinas virtuales. Para ello, editamos el fichero /etc/network/interfaces, y a√±adimos al final:\nauto vmbr1 # Nombre de la interfaz iface vmbr1 inet static address 10.10.10.1/24 # IP dentro de esta interfaz. bridge-ports none bridge-stp off bridge-fd 0 post-up echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward # Permite hacer port-forwarding para mandar puertos a VM. post-up iptables -t nat -A PREROUTING -i vmbr0 -p udp --dport 51820 -j DNAT --to 10.10.10.3:51820 # Ejemplo de mandar puerto 51820 UDP a VM. post-down iptables -t nat -D PREROUTING -i vmbr0 -p udp --dport 51820 -j DNAT --to 10.10.10.3:51820 post-up iptables -t nat -A POSTROUTING -s '10.10.10.0/24' -o vmbr0 -j MASQUERADE # Permite acceder a la red accediendo desde vmbr0 post-down iptables -t nat -D POSTROUTING -s '10.10.10.0/24' -o vmbr0 -j MASQUERADE post-up iptables -t nat -A POSTROUTING -s '10.10.11.0/24' -o vmbr0 -j MASQUERADE # Para la VPN post-down iptables -t nat -D POSTROUTING -s '10.10.11.0/24' -o vmbr0 -j MASQUERADE post-up iptables -t nat -A PREROUTING -i vmbr0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 10.10.10.4:80 # Manda el tr√°fico del 80 al balanceador de carga post-up iptables -t nat -A PREROUTING -i vmbr0 -p tcp -m tcp --dport 443 -j DNAT --to-destination 10.10.10.4:443 # Manda el tr√°fico del 443 al balanceador de carga.  Finalmente, ejecutamos service networking restart y tendremos una red virtual privada creada para nuestras m√°quinas virtuales.\nCreando template con Debian 10 Proxmox. Ejecutamos el siguiente script para crear un template con Debian 10 con soporte para Cloud Init:\nwget https://cdimage.debian.org/cdimage/openstack/current/debian-10-openstack-amd64.qcow2 # Create a VM qm create 9110 --name debian10-cloud --memory 2048 --net0 virtio,bridge=vmbr1 # Import the disk in qcow2 format (as unused disk) qm importdisk 9110 debian-10-openstack-amd64.qcow2 local -format qcow2 # Attach the disk to the vm using VirtIO SCSI qm set 9110 --scsihw virtio-scsi-pci --scsi0 /var/lib/vz/images/9110/vm-9110-disk-0.qcow2 # Important settings qm set 9110 --ide2 local:cloudinit --boot c --bootdisk scsi0 --serial0 socket --vga serial0 # The initial disk is only 2GB, thus we make it larger qm resize 9110 scsi0 +30G # Using a dhcp server on vmbr1 or use static IP qm set 9110 --ipconfig0 ip=10.10.10.2/24,gw=10.10.10.1 # user authentication for 'debian' user (optional password) qm set 9110 --sshkey ~/.ssh/id_rsa.pub # check the cloud-init config qm cloudinit dump 9110 user # create tempalte and a linked clone qm template 9110  En este punto, tendremos un template con Debian 10, listo para ser clonado en nuestras nuevas m√°quinas virtuales.\nCreando m√°quinas con Terraform. En la carpeta donde vayamos a escribir los ficheros de Terraform, creamos un fichero versions.tf con el siguiente contenido:\nterraform { required_providers { proxmox = { source = \u0026quot;Telmate/Proxmox\u0026quot; version = \u0026quot;\u0026gt;=1.0.0\u0026quot; } } required_version = \u0026quot;\u0026gt;= 0.13\u0026quot; }  Este fichero, le dir√° a Terraform que plugins usar, a continuaci√≥n creamos el fichero main.tf:\nprovider \u0026quot;proxmox\u0026quot; { pm_api_url = \u0026quot;https://\u0026lt;ip publica\u0026gt;:8006/api2/json\u0026quot; pm_user = \u0026quot;root@pam\u0026quot; pm_tls_insecure = true }  Este bloque, te permitir√° conectarte a tu Proxmox, para generar m√°quinas f√°cilmente. Ejecutamos terraform init y ya podremos empezar a trabajar.\nVPN (Wireguard): Acceder desde fuera a la red virtual. Configuraci√≥n Terraform: resource \u0026ldquo;proxmox_vm_qemu\u0026rdquo; \u0026ldquo;vpn\u0026rdquo; { name = \u0026ldquo;vpn\u0026rdquo;\n target_node = \u0026quot;xxxx\u0026quot; os_type = \u0026quot;cloud-init\u0026quot; clone = \u0026quot;debian10-cloud\u0026quot; memory = 512 cores = \u0026quot;1\u0026quot; sshkeys = \u0026quot;\u0026lt;tu clave SSH\u0026gt;\u0026quot; ipconfig0 = \u0026quot;ip=10.10.10.3/32,gw=10.10.10.1\u0026quot; # Aqu√≠ configuramos la IP privada de nuestra VM bootdisk = \u0026quot;scsi0\u0026quot; disk { type = \u0026quot;scsi\u0026quot; storage = \u0026quot;local\u0026quot; size = \u0026quot;35G\u0026quot; } lifecycle { ignore_changes = [ network, ] } }  Ejecutamos terraform apply para que cree la m√°quina, y una vez que se haya creado la m√°quina, entraremos para instalar y configurar wireguard:\n  Ejecutamos sudo apt update\n  Ejecutamos sudo apt upgrade\n  Activamos el repositorio de backports, que es donde se aloja wireguard: sudo sh -c \u0026quot;echo 'deb http://deb.debian.org/debian buster-backports main contrib non-free' \u0026gt; /etc/apt/sources.list.d/buster-backports.list\u0026quot;\n  Volvemos a actualizar nuestros repositorios: sudo apt update\n  Instalamos wireguard: sudo apt install wireguard\n  Entramos en /etc/wireguard/; cd /etc/wireguard/\n  Generamos las claves privadas y p√∫blicas del servidor: umask 077; wg genkey | tee privatekey | wg pubkey \u0026gt; publickey\n  Creamos el fichero wg0.conf:\n [Interface] Address = 10.10.11.1/24 # IP de los clientes y servidor de la VPN ListenPort = 51820 PrivateKey = \u0026lt;contenido fichero /etc/wireguard/privatekey\u0026gt; PostUp = iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE; iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT # Permitimos a los clientes acceder a la red privada.    En nuestro ordenador local instalamos wireguard, y accedemos a /etc/wireguard/ y seguidamente, ejecutamos umask 077; wg genkey | tee privatekey | wg pubkey \u0026gt; publickey\n  Volvemos, al servidor y copiamos la clave p√∫blica del cliente, y creamos un peer de wireguard:\n[Peer] PublicKey = \u0026lt;Clave p√∫blica del cliente\u0026gt; AllowedIPs = 10.10.11.2/24 # IP del cliente    Iniciamos wireguard en la m√°quina virtual: systemctl enable wg-quick@wg0 --now\n  En nuestro ordenador local, terminamos de configurar wireguard, creamos el fichero /etc/wireguard/wg0.conf\n[Interface] Address = 10.10.11.2/24 # IP del cliente DNS = 8.8.8.8 PrivateKey = \u0026lt;Private key de nuestra m√°quina\u0026gt; [Peer] PublicKey = \u0026lt;Public key del servidor\u0026gt; AllowedIPs = 10.10.10.0/24 # IPs que van a pasar por la VPN, en nuestro caso 10.10.10.0/24 porque son las de vmbr1 Endpoint = \u0026lt;ip publica servidor\u0026gt;:51820 PersistentKeepalive = 25    Iniciamos en local la VPN: systemctl enable wg-quick@wg0 --now\n  Otras m√°quinas necesarias Se crear√°n 4 m√°quinas virtuales m√°s:\n Balancer, una m√°quina con debian 10 con la IP 10.10.10.4, que ser√° un worker de de Kubernetes donde ejecutaremos simplemente el NGINX Ingress (1GB de RAM | 1 CPU) 2 rancher-nodes, donde desplegaremos etcd, controlplane y los pods del cl√∫ster. (2GB de RAM | 2 CPU) Rancher, panel de administraci√≥n de K8s. (2GB de RAM | 1 CPU)  Kubernetes f√°cilmente: Rancher Instalando Rancher Rancher puede instalarse directamente en un cl√∫ster existente de Kubernetes, podemos desplegarlo dentro de K3s, o simplemente ejecutarlo desde docker. En un entorno de producci√≥n no es recomendable instalar rancher directamente desde docker, a√∫n as√≠, para mi caso, que no es un entorno cr√≠tico, lo instalar√© directamente en docker para ahorrarme recursos:\n Creamos la m√°quina para rancher, que tendr√° la IP 10.10.10.5 Instalamos docker, sudo apt update; sudo apt install docker.io Ejecutamos e instalamos rancher: docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher:latest  Esperamos, un tiempo y podremos acceder al panel de rancher por primera vez:   Rancher setup \nUna vez terminada la configuraci√≥n inicial, veremos el listado de todos los cl√∫sters de K8s administrados desde rancher, en este momento, s√≥lo veremos uno local, que es el propio cl√∫ster de Rancher. Nuestra siguiente tarea ser√° crear un cl√∫ster de Kubernetes para las dos m√°quinas nuevas que hemos creado:\nCreando un nuevo cl√∫ster de Kubernetes. Desde la interfaz de rancher, hacemos click sobre Add cluster, y veremos la siguiente interfaz:   Nuevo cl√∫ster  En mi caso, voy a lanzar un nuevo cl√∫ster en Existing nodes, pero si nuestra infraestructura est√° desplegada en otro proveedor, podemos tambi√©n desplegarla f√°cilmente desde rancher. En mi cl√∫ster, he a√±adido la siguiente configuraci√≥n:\n **Nombre: ** my-kube **Network provider: **: calico  Una vez rellenada esta configuraci√≥n, nos mostrar√° una pantalla con un comando que debemos ejecutar en las m√°quinas que queremos que formen parte del cl√∫ster. En un entorno de producci√≥n es recomendable instalar etcd, controlplane y worker por separado. Para mi caso particular, que es un entorno \u0026ldquo;para mi\u0026rdquo;, voy a instalar etcd, controlplane y worker en la misma m√°quina:\nsudo apt update sudo apt install docker.io sudo docker run -d --privileged --restart=unless-stopped --net=host -v /etc/kubernetes:/etc/kubernetes -v /var/run:/var/run rancher/rancher-agent:v2.5.5 --server https://10.10.10.5 --token xxxxx --ca-checksum xxxxx --etcd --controlplane --worker  A medida que ejecutamos este comando en todas las m√°quinas, veremos como nuestros nodos pasar√°n a formar parte del nuevo cl√∫ster de Kubernetes que hemos creado:   Nuevo cl√∫ster \nEn este punto, nos toca tener paciencia y esperar a que los nodos terminen de desplegarse\u0026hellip; Cuando terminen de desplegarse, veremos lo siguiente:   Nuevo cl√∫ster \nPrimeras configuraciones  Creamos un nuevo proyecto d√≥nde desplegaremos las aplicaciones de josecarlos.me, tungsteno.app y demo.tungsteno.app  Buscamos en el men√∫ Project/Namespaces Le damos a Add project Creamos un nuevo proyecto, y accedemos al administrador del proyecto.    Desplegando mis aplicaciones En primer lugar, vamos a desplegar josecarlos.me. Accedemos a workloads, veremos la siguiente interfaz:   Nuevo cl√∫ster \nHacemos click sobre Deploy, y desplegamos el pod con la imagen Docker de nuestra aplicaci√≥n:   Nuevo cl√∫ster .\nConfiguramos un balanceador de carga para mandar josecarlos.me hacia el pod creado anteriormente. Entramos en primer lugar sobre load balancing, seguidamente hacemos click sobre Add ingress:\n  Nuevo cl√∫ster .\nRepitiendo el proceso para tungsteno.app, habremos terminado.\nConclusiones ","description":"","image":"cover.jpeg","permalink":"https://josecarlos.me/p/mi-nueva-infraestructura/","subtitle":null,"tags":["ops","proxmox","kubernetes","private-network","wireguard"],"title":"Mi nueva infraestructura. Proxmox + Private Network + Terraform + VPN + Kubernetes (Rancher)"},{"content":"","description":null,"image":"ia.jpeg","permalink":"https://josecarlos.me/categories/ia/","subtitle":null,"tags":null,"title":"Inteligencia artifical"},{"content":"","description":null,"image":"ram.jpeg","permalink":"https://josecarlos.me/categories/ops/","subtitle":null,"tags":null,"title":"Operaciones"},{"content":"¬øQu√© es Varnish? Varnish es un sistema de cache que se utiliza principalmente para cubrir las siguientes necesidades:\n Cachear nuestros sitios webs para reducir la carga del backend. Acelerar la carga de est√°ticos para cargarlo directamente en la RAM. \u0026hellip;  Varnish tiene una documentaci√≥n bastante completa que es p√∫blica para todo el mundo y podemos consultar directamente en:\n https://varnish-cache.org/docs/6.5/  Una de las configuraciones m√°s interesantes de Varnish nos permite configurar cuanto tiempo debe de estar un objeto en la cache.\nConfiguraci√≥n en varnish de tiempos de cache En la documentaci√≥n de varnish podemos encontrar como configurar los tiempos que se mantendr√° un objeto en la cache.\nEn este caso, nos vamos a centrar en beresp.ttl y beresp.grace\nberesp.ttl Esta configuraci√≥n nos permite configurar cuanto tiempo debe de estar un objeto en la cache. Cuando pase este tiempo, el objeto dejar√° de servirse desde la cache (Si no tenemos configurado beresp.grace). Por ejemplo, si configuramos set beresp.ttl=1h, cuando pase una hora, el fichero se volver√° a pedir al backend.\nberesp.grace Esta configuraci√≥n nos permite configurar un periodo de gracia que nos permitir√° seguir mostrando a los usuarios versiones caducadas de la cache, mientras que varnish consulta al backend por una versi√≥n actualizada.\nVentajas de usar beresp.grace Una vez introducidas estas dos configuraciones, se van a mostrar dos ejemplos para que el lector entienda la necesidad del uso de beresp.grace.\nSupongamos que tenemos un fichero HTML fichero.html con un TTL de 1h y beresp.grace de 24h.\nEjemplo 1: Mucho tr√°fico  Supongamos que fichero.html no se encuentra en la cache actualmente, y que un cliente accede a misitio.com/fichero.html, en este caso,** Varnish ir√° al backend y pedir√° la versi√≥n m√°s nueva de fichero.html**, y **la guardar√° en cache.** Si otro cliente accede en la pr√≥xima hora a misitio.com/fichero.html, recibir√° la versi√≥n de fichero.html que tiene varnish guardada en la cache. Supongamos que cuando caduca el fichero de la cache, entran 100 usuarios simultaneos en nuestro sitio web. Si no tenemos configurado el beresp.grace, a nuestro backend llegar√≠an 100 peticiones, ya que la cache ha caducado. Sin embargo, si tenemos configurado el beresp.grace** los 100 clientes recibir√°n la versi√≥n que esta en cache de fichero.html**, y **seguidamente ir√° al backend y tratar√° de encontrar una versi√≥n actualizada de fichero.html**, pero en este caso, **s√≥lo se har√° una petici√≥n al backend**, ya que al estar dentro del per√≠odo de gracia. **Cuando el backend responda a Varnish, Varnish guardar√° esta respuesta como la cache m√°s nueva.** Finalmente, cuando acceda un usuario nuevo, Varnish mandar√° el nuevo fichero.html que ha guardado en la cache.  Ejemplo 2: Sitio online 24/7  Supongamos que fichero.html no se encuentra en la cache actualmente, y que un cliente accede a misitio.com/fichero.html, en este caso,** Varnish ir√° al backend y pedir√° la versi√≥n m√°s nueva de fichero.html**, y **la guardar√° en cache.** Supongamos que despu√©s de que se haya cargado en cache, se cae nuestro backend. Debido a que tenemos configurado un periodo de gracia de 24h, Varnish mostrar√° la versi√≥n que tiene en cache durante 24h, y tratar√° de actualizar la cache en segundo plano, cuando el sitio est√© disponible. Los usuarios podr√°n seguir viendo la web online, ya que Varnish est√° sirviendola. Supongamos que el backend vuelve a estar activo a las 12h, Varnish se conectar√° al backend, y autom√°ticamente refrescar√° la cache con las versi√≥n actualizada de fichero.html  ","description":"","image":"covevr.jpeg","permalink":"https://josecarlos.me/p/varnish-mostrar-la-cache-cuando-se-caiga-el-backend/","subtitle":null,"tags":["ops","performance","varnish"],"title":"Varnish: ¬øC√≥mo mantengo un sitio siempre online y evitos peticiones extras al backend?"},{"content":"Un poco sobre mi ¬°Hola, mundo! Bienvenid@ a mi p√°gina personal, ya que est√°s por aqu√≠, perm√≠teme que te cuente un poco sobre mi, y un poco sobre el blog üòÅ\nSobre mi Me llamo Jos√© Carlos, y en el momento que estoy escribiendo esta entrada tengo 25 a√±os. Estoy graduado en Matem√°ticas, y soy un apasionado de la inform√°tica general.\nDesde que era bastante peque√±o me ha gustado trastear, aprender y romper ordenadores. Esto hizo que desde muy temprana edad mostrase inter√©s por la programaci√≥n. Tuve mi primer ordenador con apenas 6 a√±os üë∂, y con apenas 9 a√±os la programaci√≥nüë®‚Äçüíª me empez√≥ a despertar curiosidad. Junto a un amigo del colegio empezamos a crear p√°ginas webs est√°ticas gracias a servicios como Palimpalem. Cuando las p√°ginas est√°ticas se me empezaron a quedar cortas, empec√© a trastear con PHP y comenc√© a a√±adir un poco de interactividad a mis antiguas p√°ginas est√°ticas gracias a servicios como MiArroba, que eran gratuitos y antes no me pod√≠a permitir üò≠.\nM√°s adelante, empec√© a explorar otro mundo bastante completo como es el de las CMS, mis primeros pasos fueron con Joomla!, y me ayud√≥ para a crear una p√°gina, a√∫n se puede encontrar en web.archive.org una copia de lo que fue mi primera web con Joomla! y se puede visitar aqu√≠\nA la par de estas aventuras, comenz√≥ unas de mis experiencias m√°s fructiferas en el mundo de internet gracias a Kekomundo, un foro donde se desarrollaban servidores para copias de juegos online. En este mundo me di a conocer con varios proyectos, que muchos nost√°lgicos conocer√°n, y me hizo estar relacionado muchos a√±os con Habbo Hotel.\nDe esta relaci√≥n con Habbo Hotel, se desat√≥ mi pasi√≥n por la seguridad inform√°tica y por las matem√°ticas, y creo que fue el momento donde realmente me di cuenta que ten√≠a que aprender m√°s matem√°ticas para complementar mi formaci√≥n que hab√≠a desarrollado a√±os atr√°s gracias a la curiosiad. En esta √©poca encontr√© una serie de exploits dentro del cliente de Habbo Hotel que permit√≠an hacer un Man-in-the-middle, debido a los problemas que exist√≠an en la implementaci√≥n del cliente, en la librer√≠a Diffie-Hellman y m√°s adelante usando teƒánicas de detecci√≥n de patrones buscando en la memoria RAM.\n  NovoFatum \nDespu√©s de unos a√±os muy divertidos y fruct√≠feros, abandon√© por completo este mundo para dedicarme plenamente al desarrollo de software libre, mis estudios y mi trabajo.\nCuando estaba en tercero de carrera, empec√© a trabajar como desarrollador de software, donde tambi√©n realizaba, operaciones y tareas de monitorizaci√≥n. Fueron 3 a√±os muy fructifero, y m√°s all√° de que fuera mi primera experiencia profesional, me sirvi√≥ para aprender much√≠simo del mundo Linux y me ayud√≥ para desarrollar mi creatividad.\nA d√≠a, de hoy estoy empezando una nueva aventura laboral, y estoy trabajando en un proyecto de software libre que se llama Tungsteno, que trata de crear una alternativa libre para el Wolfram Mathematica. üòÅ\n","description":"üìè + üî¨ + üë®‚Äçüíª + üö¥ + üêß + ‚òÅÔ∏è = ‚ù§Ô∏è","image":"history.jpeg","permalink":"https://josecarlos.me/sobre-mi/","subtitle":null,"tags":null,"title":"Sobre mi"},{"content":"Cuando nos hablan de inteligencia artificial, nos asustamos y pensamos en primera instancia que estos conocimientos est√°n lejos de la mano de los mortales.\nEn estas entradas voy a tratar de introducir de manera intuitiva los conceptos b√°sicos del machine learning y presentar algunas implementaciones y aplicaciones, con el objetivo de aprender yo mismo, y que otra gente aprenda.\nEn este art√≠culo tratamos uno de los modelos m√°s b√°sicos, la regresi√≥n lineal.\nPhoto by Drew Beamer/ UnsplashPredicciones b√°sicas Supongamos que nos vamos a mudar a Boston, y estamos observando la relaci√≥n entre el n√∫mero de habitaciones y el precio de las viviendas.\nRecopilaci√≥n de datos Anotamos en una tabla los valores que hemos observado:\n   Precio vivienda N¬∫ de habitaciones     24.0 6.575   21.6 6.421   34.7 7.185   33.4 6.998   36.2 7.147   28.7 6.43   22.9 6.012   27.1 6.172   16.5 5.631   18.9 6.004    Un primer acercamiento que podemos hacer es dibujar una nube de puntos donde el eje de las X corresponda al n√∫mero medio de habitaciones, y el eje de las Y corresponda al precio medio de la vivienda.\n  Una primera opci√≥n para resumir estos datos, es dibujar una recta que pase cerca de todos los datos, pero, ¬øC√≥mo podemos hacerlo? ¬øPodemos tantear la soluci√≥n?\nParece que tratar de solucionar este problema por tanteo, no es factible, tratemos de buscar una soluci√≥n aplicando las matem√°ticas.\nRecta de regresi√≥n lineal Queremos calcular una recta que minimice los errores entre todos los puntos Si calculamos la media de estos errores y los elevamos al cuadrado, obtenemos lo que se denomina error cuadr√°tico medio, y la recta que cumple esta propiedad se denomina recta de regresi√≥n lineal.\nF√≥rmulas para el c√°lculo de hiperplanos de regresi√≥n Si $X$ es la matriz de variables con una columna de $1$ en la primera columna, e $Y$ son los datos que tenemos y queremos predecir. Si observamos el caso de las viviendas en Boston, la matrix $X$ tendr√≠a dos columnas, una s√≥lo con 1, y otra con la media de n√∫mero de habitaciones, por otro lado, la $Y$ ser√≠an los precios de las viviendas.\nEntonces, el hiperplano $Y_e=\\beta X$ (O recta en $\\mathbb{R}^2$) tiene las siguientes componentes: $$ \\beta = (X^T X)^{-1} X^T Y $$\nDado que la primera columna de $X$ est√° compuesta por 1, el hiperplano vendr√° definido por: $$ Y_e = \\beta_1 X + \\beta_0 $$ Donde $\\beta_i$ son las componentes del vector $\\beta$\nPrediciendo valores Si volvemos a nuestro caso especifico, vamos a calcular los valores $\\beta$ y $\\alpha$.\nNuestra matrices $X$ e $Y$, vienen definidas de la siguiente forma:\n$$ X=\\left(\\begin{matrix} 1 \u0026amp; 6.575 \\\n1 \u0026amp; 6.421 \\\n1 \u0026amp; 7.185 \\\n1 \u0026amp; 6.998 \\\n1 \u0026amp; 7.147 \\\n1 \u0026amp; 6.43 \\\n1 \u0026amp; 6.012 \\\n1 \u0026amp; 6.172 \\\n1 \u0026amp; 5.631 \\\n1 \u0026amp; 6.004 \\end{matrix}\\right), Y=\\left(\\begin{matrix} 24.0 \\\n21.6 \\\n34.7 \\\n33.4 \\\n36.2 \\\n28.7 \\\n22.9 \\\n27.1 \\\n16.5 \\\n18.9 \\end{matrix}\\right) $$\nPor tanto, $$\\beta=(-49.98256497, 11.82850406)$$ De donde, $$ y_e=x b_1 + b_0 $$\nPodemos pintar la recta con los gr√°ficos para ver como se ajusta la recta: Supongamos ahora, que queremos calcular el precio estimado de una vivienda de 8 habitaciones, ahora simplemente deber√≠amos sustiuir en nuestra recta otros valores, y tendr√≠amos: $$ y_e = 8 \\beta_1 + \\beta_0 = 44 $$\nPor lo cual, predecimos que valor de una vivienda de 8 habitaciones, tendr√° un precio aproximadamente de 44k$\nPhoto by Hernan Lucio/ UnsplashC√°lculo de recta de regresi√≥n lineal Python Para este ejemplo utilizaremos la librer√≠a de c√°lculo cient√≠fico numpy, se puede encontrar el ejemplo aqu√≠:\n Ejemplo b√°sico con Numpy Usando funciones ya existentes para calcular la recta de regresi√≥n  Limitaciones En el ejemplo espec√≠fico de los precios de las viviendas en Boston seg√∫n el n√∫mero de habitaciones, se puede observar que los datos est√°n m√°s o menos cercanos a la recta de regresi√≥n que hemos calculado, y que la nube de puntos se \u0026ldquo;asemeja\u0026rdquo; a una recta. Sin embargo, esto no es siempre as√≠. Podr√≠a ocurrir que nuestros datos est√©n sumamente dispersos, y que nos fuese imposible encontrar una recta de regresi√≥n donde el error m√≠nimo sea demasiado grande.\nEs por eso, que se ver√°n otros modelos m√°s complejos que tratan de solucionar esto.\nAplicaciones Como hemos observado, estos modelos son muy b√°sicos y presentan limitaciones, sin embargo son bastante potentes en ciertas situaciones para predecir comportamientos.\nPor ejemplo, podemos usar este modelo para predecir m√©tricas en bases de datos temporales como Prometheus\nPrediciendo el futuro con Prometheus Prometheus incluye dos funciones interesante en este sentido predict_linear que predice el valor de una serie temporal en el futuro usando regresi√≥n lineal.\nEsta funci√≥n nos puede servir para tantear el valor que tendr√° una m√©trica en el futuro. Por ejemplo, si tenemos una m√©trica que cuenta la cantidad de usuarios conectados durante una campa√±a, podremos saber cuantos usuarios habr√° dentro de un periodo de tiempo.\nPor otro lado, tenemos la funci√≥n deriv, que nos devuelve la pendiente de la recta de regresi√≥n lineal.\nEsta pendiente nos permite calcular la velocidad con la que se est√° moviendo nuestra serie temporal y hacia que direcci√≥n. Por ejemplo, si tenemos una m√©trica que cubre el porcentaje de disco duro libre, y hacemos su derivada en los √∫ltimos 30 minutos, y nos da un valor negativo, podremos saber que se est√°n escribiendo ficheros en el disco, adem√°s, dado que la pendiente de la recta modela la velocidad de crecimiento (o decrecimiento) de nuestros datos, podremos sacar conclusiones de cuando pasar√° algo. Photo by Luke Chesser/ UnsplashFuente / Enlaces de inter√©s https://en.wikipedia.org/wiki/Linear_regression\nhttps://docs.scipy.org/doc/numpy/reference/routines.linalg.html\nhttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\nhttps://docs.scipy.org/doc/numpy/index.html\nhttps://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html\n  ","description":"","image":"cover.jpeg","permalink":"https://josecarlos.me/p/ia-1-introduccion/","subtitle":null,"tags":["ia","python","tensorflow"],"title":"Inteligencia Artificial: #1 Introducci√≥n, rectas de regresi√≥n"},{"content":"","description":null,"image":null,"permalink":"https://josecarlos.me/archives/","subtitle":null,"tags":null,"title":"Archives"}]